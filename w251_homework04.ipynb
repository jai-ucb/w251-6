{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFZDObihK0-I"
   },
   "source": [
    "## Homework 04\n",
    "  \n",
    "The [Conversation AI](https://conversationai.github.io/) team, a research initiative founded by [Jigsaw](https://jigsaw.google.com/) and Google (both a part of Alphabet) are working on tools to help improve online conversation. One area of focus is the study of negative online behaviors, like toxic comments (i.e. comments that are rude, disrespectful or otherwise likely to make someone leave a discussion).   \n",
    "  \n",
    "In 2019, Kaggle hosted their [second competition](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge#description) on this research. The challenge was to create a model that is capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models. The competitions used a dataset of comments from Wikipedia’s talk page edits. Improvements to the current model will hopefully help online discussion become more productive and respectful.\n",
    "\n",
    "We shall be using this dataset to benchmark a number of ML models. While the focus of the current competition is to mitigate bias, we will not be using the metric used in the competition. Instead we will be focusing on a simpler metric [Area under the Curve (or AUC)](https://www.kaggle.com/learn-forum/53782) which is suitable to unbalanced binary datasets. Also, we shall not consider different levels of Toxicity; we shall purely take anything marked over the 0.5 level in the measured toxicity range as toxic, and anything underneath as non-toxic. \n",
    "\n",
    "We have created a jupyter notbook with some of the tools to model this problem in Deep Learning, using Logistic regression and MLP. Your challenge will be to fill in the models and benchmark the AUC you achieve on these models.\n",
    "\n",
    "We shall be using the keras deep learning package. As you may know, this is an API into DL frameworks, but is most commonly backed by Tensorflow. [keras.io](keras.io) is a great source for documentation and examples on layers available andn functionality. \n",
    "\n",
    "**Have fun!!**\n",
    "\n",
    "\n",
    "*Disclaimer: the dataset used contains text that may be considered profane, vulgar, or offensive.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E08neqFpK0-N"
   },
   "source": [
    "### Set up packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMlhL7BpK0-N"
   },
   "outputs": [],
   "source": [
    "# Unfortunately the latest Keras version has a bug with Sparse matrices and we need to downgrade. \n",
    "# !pip install tensorflow==1.14\n",
    "# !pip install keras==2.2.5\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2W19KnfK0-O"
   },
   "source": [
    "### Load data\n",
    "Let's load our data and take a peak.   \n",
    "The competition metrics and fields have too much detail to cover here.   \n",
    "We will just focus on the comment of the users and whether it was deemed toxic (target>0.5) or not.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNrAyt3RK0-O",
    "outputId": "9e2274cb-8346-461e-a807-7206952d40e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-02 23:39:13--  https://www.dropbox.com/s/xei6z41mfrcnxcd/train.csv.zip?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6017:18::a27d:212\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/dl/xei6z41mfrcnxcd/train.csv.zip [following]\n",
      "--2021-02-02 23:39:13--  https://www.dropbox.com/s/dl/xei6z41mfrcnxcd/train.csv.zip\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucd4facfd72c719b575d1e19cb76.dl.dropboxusercontent.com/cd/0/get/BIO7mjcKYmDbK5ZAvZ5wL3fmZFnfK3K7cSkW7WtE-vXCUZGWrwUmthBd9lD99V6iTlCWEUzEimeSxqqMOjJBVShyEhYLUuA-723q48B9IyfSg-sZMwbdAxEviSafIjBc5Nw/file?dl=1# [following]\n",
      "--2021-02-02 23:39:14--  https://ucd4facfd72c719b575d1e19cb76.dl.dropboxusercontent.com/cd/0/get/BIO7mjcKYmDbK5ZAvZ5wL3fmZFnfK3K7cSkW7WtE-vXCUZGWrwUmthBd9lD99V6iTlCWEUzEimeSxqqMOjJBVShyEhYLUuA-723q48B9IyfSg-sZMwbdAxEviSafIjBc5Nw/file?dl=1\n",
      "Resolving ucd4facfd72c719b575d1e19cb76.dl.dropboxusercontent.com (ucd4facfd72c719b575d1e19cb76.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
      "Connecting to ucd4facfd72c719b575d1e19cb76.dl.dropboxusercontent.com (ucd4facfd72c719b575d1e19cb76.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 286248352 (273M) [application/binary]\n",
      "Saving to: ‘train.csv.zip’\n",
      "\n",
      "train.csv.zip       100%[===================>] 272.99M   100MB/s    in 2.7s    \n",
      "\n",
      "2021-02-02 23:39:17 (100 MB/s) - ‘train.csv.zip’ saved [286248352/286248352]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# File with the training samples\n",
    "!wget -O train.csv.zip \"https://www.dropbox.com/s/xei6z41mfrcnxcd/train.csv.zip?dl=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0kk5D1CK0-P",
    "outputId": "4f31585b-7649-44d6-b841-fa2e129fd8db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.config', 'train.csv.zip', 'sample_data']"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at what files we have available. \n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxG2HnrUMY6z",
    "outputId": "b685b2ba-9794-443c-c4a3-51e4a1a2be1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\n",
      "drwxr-xr-x 1 root root 4096 Jan 20 17:27 sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AI6hptZjK0-P",
    "outputId": "8f06bf5c-e54d-43b2-e3d9-a9a0bf9cee24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Number of (rows, columns) : (1804874, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv.zip', \n",
    "                       dtype={'comment_text':str},\n",
    "                       usecols=['comment_text', 'target'],\n",
    "                       compression = 'zip')\n",
    "train_df['target'] = (train_df['target']>0.5).astype(int)\n",
    "print(\"Dataframe Number of (rows, columns) : {}\".format(train_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 979
    },
    "id": "qXmGza47K0-P",
    "outputId": "700582d4-eeaf-4adf-c071-dd3d59e75208"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>This is such an urgent design problem; kudos to you for taking it on. Very impressive!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Is this something I'll be able to install on my site? When will you be releasing it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>ur a sh*tty comment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>hahahahahahahahhha suck it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>FFFFUUUUUUUUUUUUUUU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>The ranchers seem motivated by mostly by greed; no one should have the right to allow their animals destroy public land.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>It was a great show. Not a combo I'd of expected to be good together but it was.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>Wow, that sounds great.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>This is a great story. Man. I wonder if the person who yelled \"shut the fuck up!\" at him ever heard it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>This seems like a step in the right direction.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>It's ridiculous that these guys are being called \"protesters\". Being armed is a threat of violence, which makes them terrorists.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>This story gets more ridiculous by the hour! And, I love that people are sending these guys dildos in the mail now. But… if they really think there's a happy ending in this for any of them, I thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>I agree; I don't want to grant them the legitimacy of protestors. They're greedy, small-minded people who somehow seem to share the mass delusion that this is not only a good idea for themselves a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>Interesting. I'll be curious to see how this works out. I often refrain from commenting because I don't have the time or desire to engage with the couple of resident trolls who seem to jump on eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>Awesome! I love Civil Comments!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm glad you're working on this, and I look forward to seeing how it plays out.    The comments sections of online news stories have the potential to be great tools for community interaction about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>Angry trolls, misogynists and Racists\", oh my. It doesn't take all of my 150 IQ to see the slant here.  it's the \"Diversity diode\" at work yet again. \"We can say anything that we want because we a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>Nice to some attempts to try to make comments better—it feels like any innovation in commenting communities ended with the launch of Disqus nearly a decade ago.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>One would hope that the purpose of introducing this system is to encourage more debate and discussion, not less.  It seems there are several things that limit the flow of discussion:  Making comme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>Comments will be randomly chosen and be reviewed by more than one person. But I bet the Civil people have an even better, more thorough answer to this question!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>She would be a major improvement for city council and she has a long history of giving all citizens a voice. She is a problem solver that is what Portland needs .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>I agree! Comments have so much potential to be places for active discussion, especially in publications that already serve an amazing community (but then, I'm biased—I'm a Civil co-founder). We've...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>Great question! It's one we're asked a lot. We've designed the system assuming that people *will* try to abuse it. So, in addition to the peer reviews, there are algorithms on the backend doing a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>Thanks, Christa!  Will you be adding any features to allow overall \"upvotes\" of the article itself?  Also, notification settings for users?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>Our aim is actually the opposite: we want spirited debate in which everyone feels free to participate, without fear of harassment, abuse, or death threats. Right now, a lot of voices are being sil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>Thanks! We're really going to try — not only to improve civility, but also to make comments more dynamic and interesting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>I applaud Civil's efforts to create some new technology in this field. Hoping for more thoughtful discussions moving forward.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target                                                                                                                                                                                             comment_text\n",
       "0        0                                                                                                    This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\n",
       "1        0                                                                                       Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!\n",
       "2        0                                                                                                                   This is such an urgent design problem; kudos to you for taking it on. Very impressive!\n",
       "3        0                                                                                                                     Is this something I'll be able to install on my site? When will you be releasing it?\n",
       "4        1                                                                                                                                                                     haha you guys are a bunch of losers.\n",
       "5        1                                                                                                                                                                                     ur a sh*tty comment.\n",
       "6        0                                                                                                                                                                              hahahahahahahahhha suck it.\n",
       "7        0                                                                                                                                                                                      FFFFUUUUUUUUUUUUUUU\n",
       "8        0                                                                                 The ranchers seem motivated by mostly by greed; no one should have the right to allow their animals destroy public land.\n",
       "9        0                                                                                                                         It was a great show. Not a combo I'd of expected to be good together but it was.\n",
       "10       0                                                                                                                                                                                  Wow, that sounds great.\n",
       "11       0                                                                                                  This is a great story. Man. I wonder if the person who yelled \"shut the fuck up!\" at him ever heard it.\n",
       "12       0                                                                                                                                                           This seems like a step in the right direction.\n",
       "13       1                                                                         It's ridiculous that these guys are being called \"protesters\". Being armed is a threat of violence, which makes them terrorists.\n",
       "14       0  This story gets more ridiculous by the hour! And, I love that people are sending these guys dildos in the mail now. But… if they really think there's a happy ending in this for any of them, I thin...\n",
       "15       0  I agree; I don't want to grant them the legitimacy of protestors. They're greedy, small-minded people who somehow seem to share the mass delusion that this is not only a good idea for themselves a...\n",
       "16       0  Interesting. I'll be curious to see how this works out. I often refrain from commenting because I don't have the time or desire to engage with the couple of resident trolls who seem to jump on eve...\n",
       "17       0                                                                                                                                                                          Awesome! I love Civil Comments!\n",
       "18       0  I'm glad you're working on this, and I look forward to seeing how it plays out.    The comments sections of online news stories have the potential to be great tools for community interaction about...\n",
       "19       0  Angry trolls, misogynists and Racists\", oh my. It doesn't take all of my 150 IQ to see the slant here.  it's the \"Diversity diode\" at work yet again. \"We can say anything that we want because we a...\n",
       "20       0                                         Nice to some attempts to try to make comments better—it feels like any innovation in commenting communities ended with the launch of Disqus nearly a decade ago.\n",
       "21       0  One would hope that the purpose of introducing this system is to encourage more debate and discussion, not less.  It seems there are several things that limit the flow of discussion:  Making comme...\n",
       "22       0                                         Comments will be randomly chosen and be reviewed by more than one person. But I bet the Civil people have an even better, more thorough answer to this question!\n",
       "23       0                                       She would be a major improvement for city council and she has a long history of giving all citizens a voice. She is a problem solver that is what Portland needs .\n",
       "24       0  I agree! Comments have so much potential to be places for active discussion, especially in publications that already serve an amazing community (but then, I'm biased—I'm a Civil co-founder). We've...\n",
       "25       0  Great question! It's one we're asked a lot. We've designed the system assuming that people *will* try to abuse it. So, in addition to the peer reviews, there are algorithms on the backend doing a ...\n",
       "26       0                                                              Thanks, Christa!  Will you be adding any features to allow overall \"upvotes\" of the article itself?  Also, notification settings for users?\n",
       "27       0  Our aim is actually the opposite: we want spirited debate in which everyone feels free to participate, without fear of harassment, abuse, or death threats. Right now, a lot of voices are being sil...\n",
       "28       0                                                                                Thanks! We're really going to try — not only to improve civility, but also to make comments more dynamic and interesting.\n",
       "29       0                                                                            I applaud Civil's efforts to create some new technology in this field. Hoping for more thoughtful discussions moving forward."
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 200\n",
    "pd.options.display.max_rows = 30\n",
    "train_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfE1xqkXK0-P"
   },
   "source": [
    "### Create validation data set\n",
    "Lets randomly 66/33 split the data into a training and validation set.   \n",
    "**No change needed here - note, please do not change the KFold split parameters, keeping it consistent will help us debug.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMLV_yWqK0-Q"
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "trn_ids, val_ids = next(cv.split(train_df))\n",
    "x_train, x_valid = train_df['comment_text'][trn_ids], train_df['comment_text'][val_ids]\n",
    "y_train, y_valid = train_df['target'].values[trn_ids], train_df['target'].values[val_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcU2jGM_K0-Q"
   },
   "source": [
    "### Vectorize Count of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Mu_6eniK0-Q"
   },
   "source": [
    "![Count Vectorizer](https://cdn-images-1.medium.com/max/1600/1*LD5XaHzOnoniU4p137FL5g.jpeg)  \n",
    "We shall start off performing some CPU based Deep Learning operations. Sparse matrices are better run on CPU.    \n",
    "Do not underestimate CPU based Deep Learning such as MLP; these models can be very powerful and outperform complex much more complex DL models.   \n",
    "Here we create a sparse matrix from the text with 200K of the most common unigram and bigrams.  \n",
    "**Your task here is to convert the collection of text documents (found in the `comment_text` field) to a matrix of token counts.  \n",
    "This can be done using the [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) in scikit_learn.  \n",
    "After creating the vectorizer, fit it based on the train matrix `x_train` and use this vectorizer to transform both the `x_train` and `x_valid` sets.   \n",
    "Create sparse matrices called `X_trn_mat` and `X_val_mat`, and please call your vectorizer: `vectorizer`.  \n",
    "Use the parameters max features = 200000 and the token pattern `\\w+`. This token pattern matches one or more word characters (same as `[a-zA-Z0-9_]`) only. All other characters are stripped.\n",
    "Also, we would like to count both unigrams and bigrams (pairs of words), so set the ngram range to `(1,2)`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PD7J5p5WJyNH",
    "outputId": "76da0436-6f49-4609-ee64-10a12ab36e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Non-Zero Features per Example : 74.21\n",
      "Average Number of Non-Zero Features per Example : 74.33\n"
     ]
    }
   ],
   "source": [
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# Create a CountVectorizer, called `vectorizer`\n",
    "# And create sparse matrices X_trn_mat & X_val_mat\n",
    "#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2), token_pattern='\\w+', max_features=200000)\n",
    "x_fit = vectorizer.fit(x_train)\n",
    "X_trn_mat = x_fit.transform(x_train)\n",
    "X_val_mat = x_fit.transform(x_valid)\n",
    "print(\"Average Number of Non-Zero Features per Example : {:.4}\".format(X_val_mat.nnz / X_val_mat.shape[0]))\n",
    "print(\"Average Number of Non-Zero Features per Example : {:.4}\".format(X_trn_mat.nnz / X_trn_mat.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mmhUutuKK0-R",
    "outputId": "bba6f08f-3369-429d-d62c-0fb7ff062f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0 0', '0 00', '0 01', '0 05', '0 1', '0 2', '0 25', '0 3', '0 4']\n",
      "['make more', 'make most', 'make much', 'make my', 'make new', 'make no', 'make noise', 'make obama', 'make of', 'make on']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names()[:10])\n",
    "print(vectorizer.get_feature_names()[100000:100000+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hycxdrJmK0-R",
    "outputId": "f5fcbd57-8c3c-4b3c-d7aa-a334567b8e5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1203249x200000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 89432534 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trn_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DtOjgw-K0-R"
   },
   "source": [
    "### Logistic Regression\n",
    "\n",
    "![Logistic Regression](https://upload.wikimedia.org/wikipedia/commons/6/6d/Exam_pass_logistic_curve.jpeg)\n",
    "  \n",
    "Lets start off with a simple Logistic Regression, which is the very basic [sigmoid activation function](https://en.wikipedia.org/wiki/Sigmoid_function) used in DL.  \n",
    "Notice we have no hidden layers, we take as input the whole sparse matrix, and as output the binary classifier prediction (`0<=output<=1`).  \n",
    "The model has 200001 parameters. One coefficient per column in the sparse matrx, plus one bias variable - each of which is learned using gradient descent. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uKrOqGycK0-R",
    "outputId": "d868f9ff-f0d9-4966-862c-1e9f10e1e2c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 200000)]          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 200001    \n",
      "=================================================================\n",
      "Total params: 200,001\n",
      "Trainable params: 200,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_in = keras.Input(shape=(X_trn_mat.shape[1],), dtype='float32', sparse=True)\n",
    "out = keras.layers.Dense(1, activation='sigmoid')(model_in)\n",
    "model = keras.Model(inputs=model_in, outputs=out)\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=1e-2))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gi4lxyEiK0-R",
    "outputId": "2d65efab-9ad5-4cc1-cdb3-7e7042ba43b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "147/147 [==============================] - 11s 67ms/step - loss: 0.3035 - val_loss: 0.1773\n",
      "Epoch 2/2\n",
      "147/147 [==============================] - 10s 64ms/step - loss: 0.1383 - val_loss: 0.1492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2153a6d588>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_trn_mat, y_train, epochs=2, batch_size=2**13, validation_data=(X_val_mat, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUwRr8qkK0-S",
    "outputId": "a55dc0b9-6de6-41e7-918f-eaa2bed7583c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score : 0.88512\n"
     ]
    }
   ],
   "source": [
    "preds_lr = model.predict(X_val_mat).flatten()\n",
    "print('AUC score : {:.5f}'.format(roc_auc_score(y_valid, preds_lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xn-K6mdsK0-S"
   },
   "source": [
    "Look at the coefficients to see which words are driving toxic and non-toxic sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DBLd32Z1K0-S",
    "outputId": "f1b0fcb9-67c7-474c-bba8-c820bcf294f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top toxic tokens : \n",
      "['crap', 'ass', 'damn', 'shit', 'stupid', 'pathetic', 'idiot', 'stupidity', 'idiots', 'idiotic']\n",
      "\n",
      "Top non-toxic tokens : \n",
      "['amen', 'well said', 'propaganda from', 'buggy', 'oh brother', 'bingo', 'law just', 'coy', 'yes just', 'accept any']\n"
     ]
    }
   ],
   "source": [
    "feats = np.array(vectorizer.get_feature_names())\n",
    "importance_index = model.get_weights()[0].flatten().argsort()\n",
    "print('Top toxic tokens : \\n{}'.format(feats[importance_index[-10:]].tolist()))\n",
    "print('\\nTop non-toxic tokens : \\n{}'.format(feats[importance_index[:10]].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Yph9EPyK0-S"
   },
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoWfgunLK0-S"
   },
   "source": [
    "![MLP](https://www.researchgate.net/profile/Mouhammd_Alkasassbeh/publication/309592737/figure/fig2/AS:423712664100865@1478032379613/MultiLayer-Perceptron-MLP-sturcture-334-MultiLayer-Perceptron-Classifier-MultiLayer.png)\n",
    "\n",
    "Here we shall create a Multi-layer perceptron. Although relatively simple, these can be very powerful models and also suited to low compute power. \n",
    "**Please add three hidden layers to the network using a `relu` activation function.  \n",
    "You can refer to this [script](https://www.kaggle.com/lopuhin/mercari-golf-0-3875-cv-in-75-loc-1900-s). This script contains an MLP which took first place in the *Mercari Price Suggestion Challenge*.   \n",
    "Note, you can do this task by only adding four lines of code. You should see a large increase in AUC over the Logistic Regression.**  \n",
    "Never underestimate the power of an MLP!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZUenu0dWslm"
   },
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSOCxbtCK0-S",
    "outputId": "249d3c7b-6d8c-4d1a-e550-ab912a383ced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 200000)]          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 192)               38400192  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                12352     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 38,416,769\n",
      "Trainable params: 38,416,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_in = keras.Input(shape=(X_trn_mat.shape[1],), dtype='float32', sparse=True)\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# Please fill in the next lines with the three hidden layers and the output layer. \n",
    "#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "out = keras.layers.Dense(192, activation='relu')(model_in)\n",
    "out = keras.layers.Dense(64, activation='relu')(out)\n",
    "out = keras.layers.Dense(64, activation='relu')(out)\n",
    "out = keras.layers.Dense(1)(out)\n",
    "model = keras.Model(inputs=model_in, outputs=out)\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iM1mphLnK0-T",
    "outputId": "fab392ba-2bc2-4c8c-d990-5493aea6e73c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "147/147 [==============================] - 60s 398ms/step - loss: 0.2156 - val_loss: 0.1429\n",
      "Epoch 2/2\n",
      "147/147 [==============================] - 62s 415ms/step - loss: 0.0905 - val_loss: 0.2494\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_trn_mat, y_train, batch_size=2**13, epochs=2, verbose=1, validation_data=(X_val_mat, y_valid))\n",
    "preds_mlp = model.predict(X_val_mat).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1rqLbImK0-T",
    "outputId": "e29dd8ea-5dd9-4733-eea9-3334eeaa6148"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score : 0.88205\n"
     ]
    }
   ],
   "source": [
    "print('AUC score : {:.5f}'.format(roc_auc_score(y_valid, preds_mlp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THG5UbKvWxzR"
   },
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6YLq6wy27hX",
    "outputId": "398732a1-442d-4e3f-8c52-5735eb542eb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 200000)]          0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                12800064  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 12,808,449\n",
      "Trainable params: 12,808,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "147/147 [==============================] - 32s 207ms/step - loss: 0.2143 - val_loss: 0.1438\n",
      "Epoch 2/2\n",
      "147/147 [==============================] - 32s 207ms/step - loss: 0.0991 - val_loss: 0.1621\n",
      "AUC score : 0.89333\n"
     ]
    }
   ],
   "source": [
    "model_in = keras.Input(shape=(X_trn_mat.shape[1],), dtype='float32', sparse=True)\n",
    "out = keras.layers.Dense(64, activation='relu')(model_in)\n",
    "out = keras.layers.Dense(64, activation='relu')(out)\n",
    "out = keras.layers.Dense(64, activation='relu')(out)\n",
    "out = keras.layers.Dense(1)(out)\n",
    "model = keras.Model(inputs=model_in, outputs=out)\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "model.summary()\n",
    "model.fit(X_trn_mat, y_train, batch_size=2**13, epochs=2, verbose=1, validation_data=(X_val_mat, y_valid))\n",
    "preds_mlp = model.predict(X_val_mat).flatten()\n",
    "print('AUC score : {:.5f}'.format(roc_auc_score(y_valid, preds_mlp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KVcI4mWWzx5"
   },
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "knQn2ET1K0-T",
    "outputId": "c1e9254b-2693-4a31-fc63-5d81de1f7eff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 200000)]          0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               51200256  \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,241,473\n",
      "Trainable params: 51,241,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "147/147 [==============================] - 82s 547ms/step - loss: 0.2031 - val_loss: 0.1459\n",
      "Epoch 2/2\n",
      "147/147 [==============================] - 80s 538ms/step - loss: 0.0929 - val_loss: 0.1946\n",
      "AUC score : 0.89977\n"
     ]
    }
   ],
   "source": [
    "model_in = keras.Input(shape=(X_trn_mat.shape[1],), dtype='float32', sparse=True)\n",
    "out = keras.layers.Dense(256, activation='relu')(model_in)\n",
    "out = keras.layers.Dense(128, activation='relu')(out)\n",
    "out = keras.layers.Dense(64, activation='relu')(out)\n",
    "out = keras.layers.Dense(1)(out)\n",
    "model = keras.Model(inputs=model_in, outputs=out)\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "model.summary()\n",
    "model.fit(X_trn_mat, y_train, batch_size=2**13, epochs=2, verbose=1, validation_data=(X_val_mat, y_valid))\n",
    "preds_mlp = model.predict(X_val_mat).flatten()\n",
    "print('AUC score : {:.5f}'.format(roc_auc_score(y_valid, preds_mlp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "okufti5FK0-T",
    "outputId": "f5215bc1-6a0a-4e59-efdf-359cb95fe2ad"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biauarAxW2MX"
   },
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIdRocJO7eZl",
    "outputId": "e75ca413-5989-4afd-90b1-2860c587cde1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 200000)]          0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                6400032   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,402,177\n",
      "Trainable params: 6,402,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "147/147 [==============================] - 24s 153ms/step - loss: 0.1998 - val_loss: 0.1477\n",
      "Epoch 2/2\n",
      "147/147 [==============================] - 22s 140ms/step - loss: 0.1067 - val_loss: 0.1829\n",
      "AUC score : 0.89049\n"
     ]
    }
   ],
   "source": [
    "model_in = keras.Input(shape=(X_trn_mat.shape[1],), dtype='float32', sparse=True)\n",
    "out = keras.layers.Dense(32, activation='relu')(model_in)\n",
    "out = keras.layers.Dense(32, activation='relu')(out)\n",
    "out = keras.layers.Dense(32, activation='relu')(out)\n",
    "out = keras.layers.Dense(1)(out)\n",
    "model = keras.Model(inputs=model_in, outputs=out)\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "model.summary()\n",
    "model.fit(X_trn_mat, y_train, batch_size=2**13, epochs=2, verbose=1, validation_data=(X_val_mat, y_valid))\n",
    "preds_mlp = model.predict(X_val_mat).flatten()\n",
    "print('AUC score : {:.5f}'.format(roc_auc_score(y_valid, preds_mlp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNE_sdoxK0-T"
   },
   "source": [
    "### MLP with regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N33om-JWK0-T"
   },
   "source": [
    "Now lets try regularization.  \n",
    "**Copy the above MLP model and create a new one adding regularization into the MLP hidden layers.  \n",
    "    Add l2 regularisation to each of the dense hidden layers. Check on [keras.io](https://keras.io) to find details on how to add l2 regularization. Play are around with different level of regularization to see when you achieve optimal results.   \n",
    "Generally it is good to choose parameters like regularization by moving up and down in factors of `10`.  \n",
    "Can you improve on your previous AUC results by using reglarisation?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQ5Bvus2W6Vh"
   },
   "source": [
    "## Model 3 Regularized - V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IljbfDX0K0-U",
    "outputId": "f1908a2b-2361-4a94-8fef-56e3821df466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 200000)]          0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               51200256  \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,241,473\n",
      "Trainable params: 51,241,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "147/147 [==============================] - 118s 786ms/step - loss: 2.3975 - val_loss: 0.5934\n",
      "Epoch 2/2\n",
      "147/147 [==============================] - 115s 776ms/step - loss: 0.5256 - val_loss: 0.4083\n",
      "AUC score : 0.90711\n"
     ]
    }
   ],
   "source": [
    "model_in = keras.Input(shape=(X_trn_mat.shape[1],), dtype='float32', sparse=True)\n",
    "out = keras.layers.Dense(256, activation='relu', kernel_regularizer='l2')(model_in)\n",
    "out = keras.layers.Dense(128, activation='relu', kernel_regularizer='l2')(out)\n",
    "out = keras.layers.Dense(64, activation='relu', kernel_regularizer='l2')(out)\n",
    "out = keras.layers.Dense(1, activation='relu', kernel_regularizer='l2')(out)\n",
    "model = keras.Model(inputs=model_in, outputs=out)\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "model.summary()\n",
    "model.fit(X_trn_mat, y_train, batch_size=2**13, epochs=2, verbose=1, validation_data=(X_val_mat, y_valid))\n",
    "preds_mlp = model.predict(X_val_mat).flatten()\n",
    "print('AUC score : {:.5f}'.format(roc_auc_score(y_valid, preds_mlp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxcegGTlXFKW"
   },
   "source": [
    "## Model 3 Regularized - V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bre8RcNP3yHJ",
    "outputId": "cb82354f-58e0-4905-9fe1-b5189723f62a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 200000)]          0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               51200256  \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,241,473\n",
      "Trainable params: 51,241,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "147/147 [==============================] - 126s 843ms/step - loss: 0.5494 - val_loss: 0.3438\n",
      "Epoch 2/2\n",
      "147/147 [==============================] - 125s 839ms/step - loss: 0.3419 - val_loss: 0.3105\n",
      "AUC score : 0.92172\n"
     ]
    }
   ],
   "source": [
    "model_in = keras.Input(shape=(X_trn_mat.shape[1],), dtype='float32', sparse=True)\n",
    "out = keras.layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001) )(model_in)\n",
    "out = keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(out)\n",
    "out = keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(out)\n",
    "out = keras.layers.Dense(1, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(out)\n",
    "model = keras.Model(inputs=model_in, outputs=out)\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "model.summary()\n",
    "model.fit(X_trn_mat, y_train, batch_size=2**13, epochs=2, verbose=1, validation_data=(X_val_mat, y_valid))\n",
    "preds_mlp = model.predict(X_val_mat).flatten()\n",
    "print('AUC score : {:.5f}'.format(roc_auc_score(y_valid, preds_mlp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpTgmXP5XGzo"
   },
   "source": [
    "## Model 3 Regularized - V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NQNqA9YrTgMY",
    "outputId": "d9bb0390-9aa5-48b8-f8f5-ee91dd886080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 200000)]          0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               51200256  \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,241,473\n",
      "Trainable params: 51,241,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "147/147 [==============================] - 127s 853ms/step - loss: 0.2861 - val_loss: 0.2323\n",
      "Epoch 2/2\n",
      "147/147 [==============================] - 121s 813ms/step - loss: 0.2032 - val_loss: 0.2278\n",
      "AUC score : 0.93279\n"
     ]
    }
   ],
   "source": [
    "model_in = keras.Input(shape=(X_trn_mat.shape[1],), dtype='float32', sparse=True)\n",
    "out = keras.layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001) )(model_in)\n",
    "out = keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001))(out)\n",
    "out = keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001))(out)\n",
    "out = keras.layers.Dense(1, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001))(out)\n",
    "model = keras.Model(inputs=model_in, outputs=out)\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=1e-3))\n",
    "model.summary()\n",
    "model.fit(X_trn_mat, y_train, batch_size=2**13, epochs=2, verbose=1, validation_data=(X_val_mat, y_valid))\n",
    "preds_mlp = model.predict(X_val_mat).flatten()\n",
    "print('AUC score : {:.5f}'.format(roc_auc_score(y_valid, preds_mlp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8DeN5UoTVduI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "w251_homework04.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
