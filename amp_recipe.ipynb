{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Automatic Mixed Precision\n",
    "*************************\n",
    "**Author**: `Michael Carilli <https://github.com/mcarilli>`_\n",
    "\n",
    "`torch.cuda.amp <https://pytorch.org/docs/stable/amp.html>`_ provides convenience methods for mixed precision,\n",
    "where some operations use the ``torch.float32`` (``float``) datatype and other operations\n",
    "use ``torch.float16`` (``half``). Some ops, like linear layers and convolutions,\n",
    "are much faster in ``float16``. Other ops, like reductions, often require the dynamic\n",
    "range of ``float32``.  Mixed precision tries to match each op to its appropriate datatype,\n",
    "which can reduce your network's runtime and memory footprint.\n",
    "\n",
    "Ordinarily, \"automatic mixed precision training\" uses `torch.cuda.amp.autocast <https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.autocast>`_ and\n",
    "`torch.cuda.amp.GradScaler <https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler>`_ together.\n",
    "\n",
    "This recipe measures the performance of a simple network in default precision,\n",
    "then walks through adding ``autocast`` and ``GradScaler`` to run the same network in\n",
    "mixed precision with improved performance.\n",
    "\n",
    "You may download and run this recipe as a standalone Python script.\n",
    "The only requirements are Pytorch 1.6+ and a CUDA-capable GPU.\n",
    "\n",
    "Mixed precision primarily benefits Tensor Core-enabled architectures (Volta, Turing, Ampere).\n",
    "This recipe should show significant (2-3X) speedup on those architectures.\n",
    "On earlier architectures (Kepler, Maxwell, Pascal), you may observe a modest speedup.\n",
    "Run ``nvidia-smi`` to display your GPU's architecture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time, gc\n",
    "\n",
    "# Timing utilities\n",
    "start_time = None\n",
    "\n",
    "def start_timer():\n",
    "    global start_time\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_max_memory_allocated()\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "\n",
    "def end_timer_and_print(local_msg):\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "    print(\"\\n\" + local_msg)\n",
    "    print(\"Total execution time = {:.3f} sec\".format(end_time - start_time))\n",
    "    print(\"Max memory used by tensors = {} bytes\".format(torch.cuda.max_memory_allocated()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple network\n",
    "----------------\n",
    "The following sequence of linear layers and ReLUs should show a speedup with mixed precision.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(in_size, out_size, num_layers):\n",
    "    layers = []\n",
    "    for _ in range(num_layers - 1):\n",
    "        layers.append(torch.nn.Linear(in_size, in_size))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "    layers.append(torch.nn.Linear(in_size, out_size))\n",
    "    return torch.nn.Sequential(*tuple(layers)).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``batch_size``, ``in_size``, ``out_size``, and ``num_layers`` are chosen to be large enough to saturate the GPU with work.\n",
    "Typically, mixed precision provides the greatest speedup when the GPU is saturated.\n",
    "Small networks may be CPU bound, in which case mixed precision won't improve performance.\n",
    "Sizes are also chosen such that linear layers' participating dimensions are multiples of 8,\n",
    "to permit Tensor Core usage on Tensor Core-capable GPUs (see `Troubleshooting<troubleshooting>` below).\n",
    "\n",
    "Exercise: Vary participating sizes and see how the mixed precision speedup changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512 # Try, for example, 128, 256, 513.\n",
    "in_size = 4096\n",
    "out_size = 4096\n",
    "num_layers = 3\n",
    "num_batches = 50\n",
    "epochs = 3\n",
    "\n",
    "# Creates data in default precision.\n",
    "# The same data is used for both default and mixed precision trials below.\n",
    "# You don't need to manually change inputs' dtype when enabling mixed precision.\n",
    "data = [torch.randn(batch_size, in_size, device=\"cuda\") for _ in range(num_batches)]\n",
    "targets = [torch.randn(batch_size, out_size, device=\"cuda\") for _ in range(num_batches)]\n",
    "\n",
    "loss_fn = torch.nn.MSELoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.4625,  1.1594, -1.8091,  ...,  0.8453,  0.6155, -1.2540],\n",
       "         [ 0.5399,  0.4214,  1.3481,  ...,  1.2287, -0.1138, -1.2123],\n",
       "         [ 0.5529, -0.5995,  0.2861,  ...,  0.5675, -0.2956, -0.8250],\n",
       "         ...,\n",
       "         [-0.6990, -0.0326,  2.1048,  ..., -0.0150,  0.7374, -2.2933],\n",
       "         [-0.4058,  0.3649, -1.1202,  ...,  0.9525, -1.9334,  0.8800],\n",
       "         [ 0.8994,  1.3147,  0.2422,  ...,  0.8190, -0.3359, -0.1576]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1332, -0.2778,  0.7885,  ..., -0.9770,  1.2424, -0.1520],\n",
       "         [ 0.9859,  0.7506, -1.9478,  ...,  0.4920,  0.4249, -1.2119],\n",
       "         [ 1.8029,  0.7296, -0.0392,  ...,  0.6088, -0.0899, -0.6875],\n",
       "         ...,\n",
       "         [ 1.2080,  1.1131, -0.3568,  ..., -1.2847, -0.4269, -0.4956],\n",
       "         [-2.6009, -1.4892, -1.4090,  ..., -2.0354, -0.0121, -0.3604],\n",
       "         [-1.4321,  0.4775,  1.4783,  ...,  1.0182,  0.9734,  0.1630]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.8467, -0.6810, -1.8795,  ..., -0.0405,  0.9422, -0.3141],\n",
       "         [-0.5302,  0.3267, -0.1357,  ...,  1.0931, -0.5338,  0.0884],\n",
       "         [ 1.9294, -0.5405,  0.4314,  ..., -0.1461,  1.1324, -0.2359],\n",
       "         ...,\n",
       "         [-1.3053,  1.1956,  0.8028,  ...,  0.0705,  0.6346,  0.3025],\n",
       "         [ 1.5626,  3.1183,  0.7109,  ..., -1.8278,  0.5351,  0.9388],\n",
       "         [-0.9202,  0.6343, -0.6522,  ...,  1.0214, -1.7485, -0.3946]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.3441,  0.3202, -1.6947,  ...,  0.6758, -1.6445,  0.7939],\n",
       "         [-0.3330,  0.6693, -0.2523,  ..., -0.8428,  0.7065, -0.5806],\n",
       "         [ 0.6118, -0.8532, -0.7436,  ...,  0.1483,  0.0593,  0.4590],\n",
       "         ...,\n",
       "         [-0.1106,  0.5807,  0.1990,  ..., -0.2148, -0.8280, -0.2562],\n",
       "         [ 0.3726,  0.9911,  0.4888,  ..., -2.2437,  0.4622,  0.5424],\n",
       "         [-0.9339, -1.3665,  0.6490,  ..., -1.3356,  0.6368, -1.0998]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.6060,  0.0064, -1.2054,  ...,  0.3035,  0.9982, -0.0333],\n",
       "         [ 0.1962,  0.5209, -0.5386,  ...,  0.9370,  0.4612,  1.7561],\n",
       "         [-1.0270, -0.4117, -0.7832,  ..., -0.0137, -0.2704,  1.0107],\n",
       "         ...,\n",
       "         [ 1.0401,  1.8317, -1.1205,  ...,  1.3289, -0.1304,  1.3397],\n",
       "         [-1.5289, -0.0360,  0.0261,  ...,  0.7687, -1.1390,  0.2714],\n",
       "         [-0.9037,  0.0590, -0.5152,  ..., -0.5061,  0.9555, -0.3338]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1305, -1.4959, -0.9158,  ...,  2.1811, -2.7359, -0.5784],\n",
       "         [ 0.6224, -1.2371,  0.2791,  ...,  1.0164, -1.8829, -0.5915],\n",
       "         [-2.0343,  0.2126, -0.7360,  ..., -0.7387, -0.8171,  0.4622],\n",
       "         ...,\n",
       "         [ 0.6963, -0.6210,  0.7082,  ...,  0.5077, -2.2609, -0.8890],\n",
       "         [ 0.7826,  0.8983,  0.8286,  ..., -0.0098,  1.0864,  0.2489],\n",
       "         [-0.4684,  0.6787, -1.2368,  ..., -0.2854, -1.1110,  0.4358]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.8942, -0.2163, -0.6842,  ...,  0.6885,  0.4007, -0.8618],\n",
       "         [-0.9584, -0.1007, -0.8186,  ..., -0.2283, -0.6851,  0.5223],\n",
       "         [-0.4793,  0.0048, -3.0784,  ...,  0.7290,  0.3247, -1.1296],\n",
       "         ...,\n",
       "         [ 0.3643,  0.2414,  0.4069,  ..., -0.4876,  0.0164, -0.2555],\n",
       "         [ 0.0183, -1.2242,  0.5088,  ...,  2.2219,  0.2894,  0.0185],\n",
       "         [-0.1380,  0.4142,  0.1831,  ...,  0.4745,  1.8266, -1.1633]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0053, -0.2418, -1.2058,  ...,  0.3658,  0.8524,  0.8861],\n",
       "         [ 0.5933,  0.8066,  2.1318,  ..., -0.1151,  0.3563, -0.6779],\n",
       "         [ 1.6305, -0.0930,  0.6580,  ...,  0.6860, -0.1627, -1.1236],\n",
       "         ...,\n",
       "         [ 0.7619,  0.6021, -1.0481,  ...,  0.1551, -0.8892,  0.5057],\n",
       "         [ 1.1496, -1.1480,  1.1199,  ..., -2.5182,  1.9934, -1.3109],\n",
       "         [-0.9393,  0.3169, -0.9222,  ...,  0.3773,  0.0190, -1.5676]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.2718,  0.0465,  1.6498,  ..., -0.2307,  0.5697, -0.9216],\n",
       "         [ 1.0489, -1.1087,  0.7879,  ...,  0.9644,  0.2109,  0.0550],\n",
       "         [-0.2955,  0.9659,  1.9923,  ..., -0.9310, -1.8740, -0.9876],\n",
       "         ...,\n",
       "         [-0.3367, -0.4453,  1.1623,  ...,  0.0268,  1.7752,  1.2980],\n",
       "         [ 0.9017,  1.3918, -0.2479,  ..., -0.3869,  0.3004,  1.2652],\n",
       "         [-2.5663,  0.6377, -0.1656,  ...,  0.1983,  0.1127, -0.3203]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-2.0692,  0.4356, -0.9572,  ..., -2.0120, -1.0250,  1.5639],\n",
       "         [ 0.1046, -1.0476,  1.1715,  ..., -1.3543, -1.0400,  0.3130],\n",
       "         [-0.4750,  0.4205, -0.3174,  ...,  0.9572, -1.5246, -0.7656],\n",
       "         ...,\n",
       "         [-0.5890,  0.3203, -1.1965,  ...,  0.1514, -0.3729,  0.5170],\n",
       "         [ 0.9142,  0.4641, -0.4186,  ...,  0.0204,  0.0377,  0.0402],\n",
       "         [ 0.9764,  0.7983,  1.0039,  ...,  0.7060,  2.3539, -0.6316]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0575,  0.5080, -0.9172,  ..., -1.5329,  1.2531,  0.3949],\n",
       "         [-0.8470, -0.5092,  0.5227,  ...,  0.7340,  1.2321, -0.5861],\n",
       "         [-0.1868,  0.3943,  1.7667,  ..., -0.8301, -0.0233,  0.9888],\n",
       "         ...,\n",
       "         [-1.2244, -0.6764, -0.7836,  ..., -2.4841,  0.8545, -0.6351],\n",
       "         [ 1.1707,  1.3922, -0.5502,  ...,  0.7483, -0.3128, -0.4086],\n",
       "         [-2.0750, -0.5405,  2.6440,  ...,  1.7447, -0.0367,  1.1834]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.4111e+00,  3.0990e-01, -2.4949e-01,  ...,  1.7197e-03,\n",
       "          -1.0256e+00,  9.5495e-01],\n",
       "         [-1.5413e+00,  2.5024e+00, -1.0282e+00,  ..., -1.2894e+00,\n",
       "          -1.3836e+00,  2.0266e-01],\n",
       "         [-4.5973e-01,  1.2029e+00, -1.0059e+00,  ...,  5.9845e-01,\n",
       "          -1.0675e-01,  3.9725e-01],\n",
       "         ...,\n",
       "         [ 1.0130e+00, -5.7897e-01, -1.6198e+00,  ...,  6.3660e-01,\n",
       "           4.2569e-01, -1.9522e+00],\n",
       "         [ 1.1782e+00, -1.6473e+00,  1.4885e+00,  ..., -7.2140e-01,\n",
       "           1.6432e-01,  3.9130e-02],\n",
       "         [ 6.9266e-02,  9.9841e-02,  6.3759e-01,  ...,  1.1284e-02,\n",
       "          -6.7921e-02, -4.1047e-01]], device='cuda:0'),\n",
       " tensor([[ 0.4321, -0.8526, -1.0257,  ...,  0.6292, -0.0599,  0.6165],\n",
       "         [-0.2978,  1.7514, -0.0051,  ..., -0.0643,  0.4547,  0.8250],\n",
       "         [-1.2439, -0.3270,  1.9855,  ..., -0.3811, -0.0360, -0.4462],\n",
       "         ...,\n",
       "         [-2.2617, -0.6839,  0.4770,  ...,  0.0614,  3.1319, -1.1840],\n",
       "         [ 1.2975,  0.8717,  1.3929,  ...,  0.6526, -0.8509, -1.0775],\n",
       "         [-0.1737, -0.9940,  2.1549,  ..., -1.3253,  2.2351, -0.4630]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.7043,  0.0940, -0.1385,  ...,  0.4645,  1.1084, -0.8046],\n",
       "         [-0.5338, -0.0063, -0.0430,  ..., -1.5690, -0.9563, -0.1705],\n",
       "         [-0.2469,  0.0725,  0.5027,  ...,  1.3923,  0.6300, -1.7293],\n",
       "         ...,\n",
       "         [ 0.6569, -0.5684, -0.6905,  ..., -0.3099, -0.7047,  1.2785],\n",
       "         [ 1.0920, -0.8685,  0.9011,  ...,  1.4786, -0.0910,  0.1200],\n",
       "         [ 1.1283,  0.2728, -0.5644,  ..., -1.2963, -0.9568,  0.3928]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.8167,  0.5293,  0.3035,  ...,  0.6757,  1.3426,  0.2224],\n",
       "         [-0.1931, -1.4971, -0.4261,  ...,  3.4626, -1.0591, -1.1119],\n",
       "         [-1.3220,  0.4979,  0.1472,  ...,  0.3614, -0.1165,  2.0816],\n",
       "         ...,\n",
       "         [ 0.3124, -0.7194, -0.4099,  ...,  0.2131, -0.3254, -1.1915],\n",
       "         [-0.0754,  0.1483,  1.3963,  ...,  0.4838, -1.2876, -0.5212],\n",
       "         [-1.3297, -0.1154, -0.3674,  ..., -0.5321, -0.5140, -0.4911]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.4840,  1.3351,  1.4941,  ..., -0.6656,  0.8199,  1.0870],\n",
       "         [-1.0258, -0.0337,  2.0742,  ...,  1.8113,  2.1362,  2.5681],\n",
       "         [-0.2915,  0.3277,  0.0545,  ...,  0.7746,  0.5473, -0.3974],\n",
       "         ...,\n",
       "         [ 0.8891,  0.2164, -0.3495,  ..., -0.3855, -0.4622, -0.7061],\n",
       "         [ 0.3115, -0.9180, -0.1268,  ..., -0.2578,  1.3982,  0.6452],\n",
       "         [-0.5950, -0.5027,  0.8525,  ...,  0.8605,  0.2980,  1.0145]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.7635,  0.7605,  1.5196,  ..., -0.0285, -0.6070, -1.0571],\n",
       "         [-0.4023,  0.5770, -0.6213,  ...,  0.2335, -0.1248, -0.7524],\n",
       "         [-0.1472, -0.3470, -0.4133,  ...,  0.1677, -0.9956, -1.0182],\n",
       "         ...,\n",
       "         [-1.4932, -0.0824, -0.6310,  ...,  1.9599, -0.4762, -0.4968],\n",
       "         [ 0.9968,  0.3185,  0.3630,  ...,  0.4802, -0.8991,  0.0557],\n",
       "         [ 1.4807, -1.3604, -0.3412,  ...,  0.2078, -0.0222, -0.4705]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.9531,  1.0221, -0.7955,  ...,  0.8277,  0.5148,  0.8542],\n",
       "         [-1.5628, -0.2091, -1.3062,  ...,  0.4647,  0.6570,  0.9956],\n",
       "         [-0.5222, -0.0323,  0.6860,  ...,  1.2353,  0.0142,  0.1333],\n",
       "         ...,\n",
       "         [ 0.8058, -0.5491, -0.3499,  ...,  0.4173,  0.8436,  0.3124],\n",
       "         [ 0.8638, -1.1120,  0.8215,  ...,  2.2396, -0.2393, -0.8631],\n",
       "         [ 1.7936, -0.5162, -1.8971,  ...,  0.3857, -1.7055,  0.9431]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.2646, -0.8331,  0.6474,  ..., -0.7746,  0.6537, -0.1195],\n",
       "         [-0.4035,  0.5006,  0.5573,  ...,  0.1463,  1.7727,  0.9708],\n",
       "         [ 1.5036, -1.4726,  0.4123,  ...,  0.6741, -1.4342,  0.8255],\n",
       "         ...,\n",
       "         [-1.7440,  1.0414, -0.6233,  ..., -1.9234,  0.7862, -1.4772],\n",
       "         [-0.8992,  0.4615, -0.9817,  ..., -1.2962, -0.5037, -1.1750],\n",
       "         [ 0.2262,  0.8028, -0.5415,  ..., -0.9755,  1.1914, -0.9101]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.9059,  0.3446,  0.2360,  ...,  0.6252, -0.1347, -0.7306],\n",
       "         [-0.3353,  1.0998,  0.1875,  ...,  0.8315, -1.9408,  0.3254],\n",
       "         [ 0.2128,  0.6676,  0.2866,  ..., -0.4512, -1.1355, -1.4295],\n",
       "         ...,\n",
       "         [-0.3041, -1.0172, -0.5686,  ..., -0.5699,  1.6125, -0.1029],\n",
       "         [ 0.2235, -1.1561, -0.4748,  ..., -0.1346,  0.2067,  0.4552],\n",
       "         [-0.0837,  0.5587, -2.4032,  ...,  0.3050,  0.7730, -0.5513]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.3843,  0.8322,  0.5303,  ..., -0.4300,  0.5205,  1.3468],\n",
       "         [-0.6137,  1.3509, -0.7476,  ..., -1.4894,  0.7151,  2.8625],\n",
       "         [-0.9711, -0.1443,  0.3483,  ...,  1.2595, -0.9576, -0.2397],\n",
       "         ...,\n",
       "         [ 1.0980, -0.1975, -1.4691,  ..., -0.2464, -0.2768, -0.2198],\n",
       "         [-0.1489, -0.7158, -0.4500,  ...,  0.7156, -0.4681, -1.3115],\n",
       "         [ 0.0254,  0.4593, -0.9006,  ..., -0.7202,  1.4893,  0.1071]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.5299, -0.9955,  0.4207,  ...,  1.5152,  0.3771,  0.7888],\n",
       "         [ 1.1948,  0.6099, -0.1285,  ...,  1.0300,  0.0890, -0.4730],\n",
       "         [ 1.2724, -2.4077, -0.0998,  ..., -0.3221,  0.4293, -1.8122],\n",
       "         ...,\n",
       "         [ 0.4299, -0.2911,  0.7427,  ...,  0.6850,  0.4124, -0.1226],\n",
       "         [-1.0012,  0.1260, -1.5317,  ..., -0.8065, -1.2338,  1.1687],\n",
       "         [ 0.4152, -0.7167,  0.6512,  ...,  0.0792, -0.6291,  0.1098]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.8590, -0.2459, -0.6725,  ..., -0.9447,  0.4240,  0.5743],\n",
       "         [ 0.1496, -0.2991,  0.3969,  ..., -1.0197, -1.1123,  1.1007],\n",
       "         [-0.3730, -0.7576,  0.4037,  ..., -0.5956,  1.9369, -0.3061],\n",
       "         ...,\n",
       "         [-1.5396,  0.3632, -0.7264,  ...,  0.0575, -0.8585,  0.2937],\n",
       "         [-0.6894,  0.1275, -1.0457,  ..., -2.4313,  0.0455, -0.7946],\n",
       "         [ 0.0722,  0.4050,  1.5532,  ..., -0.0733,  0.4018,  0.2313]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 2.2453,  0.0381, -0.7367,  ...,  0.8959,  1.2062,  0.1482],\n",
       "         [ 0.4400, -0.9194,  0.3555,  ..., -0.5045,  1.6728, -0.3788],\n",
       "         [-1.1744,  1.3751, -0.6037,  ..., -1.7350, -1.3111, -0.2401],\n",
       "         ...,\n",
       "         [-0.8612, -0.6924,  0.8079,  ...,  1.2749,  0.4427,  0.9164],\n",
       "         [ 1.0105, -1.2852, -0.6714,  ..., -1.2802,  0.6394, -0.0531],\n",
       "         [-0.4409,  0.3648, -0.9216,  ..., -1.0297,  2.9238,  0.4626]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.8174, -1.0350,  0.7678,  ..., -0.5249,  0.6301, -0.3808],\n",
       "         [ 0.2507,  0.2811, -1.0664,  ..., -2.1129,  0.2247,  1.1938],\n",
       "         [-1.3993,  0.8161, -0.2445,  ...,  0.4704,  0.5346, -1.2687],\n",
       "         ...,\n",
       "         [ 0.1112, -0.1263, -0.8110,  ..., -0.5688, -0.4112,  0.5991],\n",
       "         [-1.1923,  1.2888,  0.3360,  ...,  1.6692, -0.3870,  1.0477],\n",
       "         [-1.3999, -0.2375, -2.2040,  ...,  0.5577,  0.0642,  0.2639]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.8219, -0.8095,  0.2657,  ...,  0.3741, -0.5906,  0.3758],\n",
       "         [ 1.7328,  0.5193, -1.0866,  ...,  1.5392, -0.6820,  0.5234],\n",
       "         [ 0.0627,  0.3993,  1.7975,  ...,  1.0779,  0.5480,  0.6676],\n",
       "         ...,\n",
       "         [-1.5946,  0.6908,  1.7758,  ...,  0.3410, -0.0311, -1.0746],\n",
       "         [ 2.0758,  0.6588, -1.2446,  ...,  0.5822,  0.2370, -1.0594],\n",
       "         [-1.3840,  2.9547,  0.2996,  ..., -0.6436, -0.2840, -0.7516]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.4324, -1.7658,  0.3629,  ..., -1.8736, -0.6296, -0.9179],\n",
       "         [-0.1018,  1.1063,  1.2925,  ..., -0.7936,  0.1644,  0.4525],\n",
       "         [ 1.7815,  0.0672, -0.8910,  ..., -0.8778, -2.3318,  0.7408],\n",
       "         ...,\n",
       "         [ 0.4949, -0.5455,  1.3981,  ..., -1.6919, -0.9880, -0.5750],\n",
       "         [-0.7082,  0.9385, -1.1740,  ..., -1.8589, -0.5572, -0.4439],\n",
       "         [ 0.9306, -0.6658, -0.4500,  ..., -0.5014, -1.1974,  1.3987]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.4792, -1.0316, -1.8610,  ...,  1.1123, -0.1042, -0.7400],\n",
       "         [ 0.3467, -0.5091,  0.0162,  ..., -1.8960,  0.9508, -0.5566],\n",
       "         [ 1.1337,  0.3165, -0.8640,  ..., -0.0345,  0.6635,  1.2639],\n",
       "         ...,\n",
       "         [ 2.0422,  1.3026, -0.0617,  ..., -0.2454,  0.8184,  0.2016],\n",
       "         [ 2.0375,  0.4162, -2.5223,  ..., -0.4132, -0.7988,  0.3350],\n",
       "         [-0.2414,  0.5678,  1.3478,  ..., -0.5413, -0.7526, -0.9566]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.2808,  0.6201,  2.4064,  ..., -0.3962, -0.6345,  0.6300],\n",
       "         [-1.6285, -0.6373, -1.6360,  ...,  1.3327,  1.9082,  0.9110],\n",
       "         [-0.4533,  0.4389,  1.9184,  ...,  0.5913, -0.0886, -0.1883],\n",
       "         ...,\n",
       "         [-1.1168, -0.1240,  1.9451,  ...,  0.5545, -0.7180,  0.5893],\n",
       "         [-0.2584,  0.1668, -1.7408,  ...,  0.2164, -0.1506, -0.6885],\n",
       "         [-1.5067, -0.0307, -0.8915,  ...,  1.5707,  0.9303,  0.3611]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.5859, -0.0488,  1.8926,  ..., -0.2273,  0.4310,  0.0944],\n",
       "         [ 0.4005, -0.1064, -1.4611,  ...,  0.7167,  0.4285, -1.0205],\n",
       "         [-0.5381, -0.0039,  0.4931,  ..., -0.3640, -0.6871, -0.6487],\n",
       "         ...,\n",
       "         [-0.1756,  2.2704, -0.0186,  ...,  1.7677,  0.8093, -3.3477],\n",
       "         [-0.5748, -0.2871, -0.1423,  ...,  0.5370, -0.4024, -0.1299],\n",
       "         [ 0.2126,  0.0228,  0.2849,  ...,  0.0570,  0.6913, -0.3975]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.0824, -0.4191, -1.0127,  ..., -1.1829, -1.3600, -0.0583],\n",
       "         [-0.4456, -1.1871, -0.6708,  ..., -0.2577, -0.1046, -0.7046],\n",
       "         [ 0.0407,  0.9901, -0.5330,  ..., -1.1263, -0.0862,  0.9234],\n",
       "         ...,\n",
       "         [ 0.9971,  0.9934, -0.0738,  ...,  0.0232, -0.8000, -0.5766],\n",
       "         [ 0.1520, -0.7796, -2.1226,  ...,  0.4097,  0.2116, -1.0744],\n",
       "         [ 0.3575,  1.9205,  1.3100,  ..., -0.3078, -1.3467,  1.5807]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 5.2810e-01,  6.2376e-02, -6.8979e-01,  ...,  1.0459e+00,\n",
       "           8.6666e-02, -6.8054e-01],\n",
       "         [-8.6889e-01,  1.7120e+00, -4.6476e-01,  ..., -3.2604e-01,\n",
       "           1.5656e+00,  9.7504e-02],\n",
       "         [-7.0565e-04,  5.0976e-02,  1.3105e+00,  ...,  1.8575e-02,\n",
       "          -2.1547e-01,  6.6619e-01],\n",
       "         ...,\n",
       "         [ 1.5976e+00,  3.8957e-02, -1.1178e+00,  ...,  7.2280e-01,\n",
       "           1.3335e-03,  1.0392e+00],\n",
       "         [ 5.0689e-01,  6.4959e-01,  4.8320e-02,  ...,  2.0607e-01,\n",
       "           7.6213e-02,  7.5561e-01],\n",
       "         [-6.7499e-01, -1.0973e+00,  5.3335e-01,  ...,  7.0620e-01,\n",
       "          -9.3769e-01,  1.9973e+00]], device='cuda:0'),\n",
       " tensor([[-0.0493, -0.7488, -0.9115,  ...,  0.4730, -1.1857,  0.6926],\n",
       "         [-1.8035, -1.0969, -1.4469,  ..., -0.6365, -0.2622,  0.8087],\n",
       "         [-0.8313,  0.5381,  0.0609,  ..., -0.8512,  0.8359, -1.2157],\n",
       "         ...,\n",
       "         [-0.5526,  1.1030,  2.6659,  ...,  1.1474,  0.1086, -1.2430],\n",
       "         [ 1.3614,  1.0573,  0.1769,  ...,  0.1925, -0.8765,  0.3343],\n",
       "         [-0.8372,  0.7187,  0.7359,  ..., -0.3704,  0.7082, -1.1544]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.6985, -0.3141,  0.8178,  ...,  0.4493, -0.4858, -0.5777],\n",
       "         [ 0.8481,  0.1397,  0.1181,  ..., -0.3190,  0.4909,  1.6633],\n",
       "         [-0.2862,  0.6037, -0.1094,  ...,  0.6172,  0.4086, -0.3789],\n",
       "         ...,\n",
       "         [ 0.7063, -0.2971, -0.5543,  ..., -0.0937,  1.9480, -0.0275],\n",
       "         [-1.5187, -0.3252, -1.4797,  ..., -0.1341, -2.1568, -0.0656],\n",
       "         [-1.0756, -1.4570,  0.0247,  ...,  0.1682, -0.5461,  0.9872]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.0505,  0.9237,  0.9056,  ..., -0.5836, -0.6001, -0.9851],\n",
       "         [ 0.2652,  0.1670, -0.2332,  ...,  1.3928, -1.8468, -1.5552],\n",
       "         [-0.3907, -0.6746,  0.6935,  ..., -0.8190,  0.8264,  0.6808],\n",
       "         ...,\n",
       "         [-1.3991, -1.1136, -1.5380,  ..., -0.5393, -1.1424,  0.0760],\n",
       "         [ 0.2024, -1.5065,  0.7009,  ...,  1.5235, -1.8628, -1.1538],\n",
       "         [-0.3587, -1.2226,  0.3130,  ..., -1.1949, -0.8945, -0.2187]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.6475,  0.1844, -1.1469,  ..., -0.1914,  0.6382, -2.5988],\n",
       "         [-0.2482, -1.2018, -0.1739,  ..., -0.6761, -0.2690,  0.3301],\n",
       "         [ 0.3057, -0.6078, -1.3209,  ...,  1.2994,  0.1493,  0.0422],\n",
       "         ...,\n",
       "         [-0.5385, -1.2286, -1.6019,  ..., -1.4304,  0.3087,  1.0956],\n",
       "         [ 1.7472,  0.1245, -0.6420,  ...,  0.1523, -0.6941,  1.8400],\n",
       "         [ 0.9699, -0.8843, -0.4594,  ...,  0.4433, -0.2569, -0.7495]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.7619, -0.5287, -1.6113,  ...,  1.6875,  0.2070, -2.1627],\n",
       "         [ 0.9822, -1.5980,  0.3447,  ...,  0.7045, -1.5454,  0.1934],\n",
       "         [ 0.5304, -0.9499, -0.2348,  ..., -0.0119,  1.0846, -0.5775],\n",
       "         ...,\n",
       "         [-1.0131, -0.5845, -1.0428,  ..., -0.6298, -0.7491, -0.8353],\n",
       "         [-0.5994, -0.1877,  1.9688,  ...,  0.1947,  0.0137,  0.2315],\n",
       "         [-1.0995,  0.4689,  1.1330,  ...,  0.9860, -2.6870, -1.6339]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.9199,  0.4585, -0.2892,  ...,  1.1661,  2.8716, -0.6933],\n",
       "         [ 1.0529,  0.3463, -0.4782,  ...,  1.3597,  1.5768, -0.5494],\n",
       "         [-0.4856, -1.5291, -0.2834,  ...,  0.3894,  0.7532, -2.4895],\n",
       "         ...,\n",
       "         [-0.5558,  1.7904,  2.1706,  ..., -0.1338, -1.1624,  0.2660],\n",
       "         [ 0.5793, -0.8454, -0.5475,  ...,  1.0760,  0.0422, -0.4289],\n",
       "         [ 1.0328,  0.2892, -1.5351,  ..., -0.2766,  1.0771,  1.8952]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.2276,  1.4556,  0.7952,  ...,  1.0177,  1.2257, -0.1125],\n",
       "         [-0.4491, -0.8299,  0.1734,  ..., -0.4389,  0.7940, -1.5405],\n",
       "         [ 0.2141,  0.2715,  0.1511,  ...,  0.0424, -1.7997, -1.9326],\n",
       "         ...,\n",
       "         [-0.2886, -0.0766, -1.4529,  ..., -0.9373, -0.1903,  1.5345],\n",
       "         [-0.6920,  1.0028, -0.5030,  ...,  0.9037,  0.0448, -0.0922],\n",
       "         [-0.0506, -0.6202, -0.6018,  ...,  1.9510, -1.0191, -0.8858]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.4557,  0.3110, -0.7135,  ...,  0.6703, -1.5621,  0.6676],\n",
       "         [-0.5705, -1.4229,  0.0662,  ...,  0.6590,  1.0684, -1.0124],\n",
       "         [-0.4207,  2.4115, -0.5617,  ...,  1.6400, -1.1060,  0.7469],\n",
       "         ...,\n",
       "         [ 1.5278,  1.7928,  0.9023,  ...,  1.0870,  0.0912, -1.6608],\n",
       "         [-0.8449, -0.2129, -2.3113,  ..., -1.3914, -0.5255,  0.7765],\n",
       "         [ 0.4432, -0.6375, -1.4367,  ..., -0.2048,  1.7415,  0.0986]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.4010,  0.1066,  0.5919,  ..., -0.8252, -0.9456, -0.9618],\n",
       "         [-0.3080, -1.5049, -1.1275,  ...,  2.8778, -0.5292,  1.3674],\n",
       "         [-1.2043,  0.6115, -0.1987,  ...,  0.0857, -1.3470, -0.2968],\n",
       "         ...,\n",
       "         [ 0.0413,  1.3625, -0.4146,  ...,  0.8696,  1.4363,  1.1430],\n",
       "         [ 1.0128,  0.3573, -0.6440,  ...,  0.6503,  0.1893,  0.2260],\n",
       "         [-0.5845, -0.9088, -0.8203,  ...,  0.3231,  0.6961, -2.0800]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.8129,  0.0701, -1.3170,  ..., -0.5903, -0.6506, -0.1777],\n",
       "         [-1.1908,  0.2001, -1.0895,  ..., -0.2216,  0.4976, -1.9209],\n",
       "         [-0.4758, -1.0154, -1.5803,  ...,  0.9834,  0.9679, -0.4124],\n",
       "         ...,\n",
       "         [-0.0428,  1.1021,  0.3223,  ...,  0.1443, -0.3862, -0.4824],\n",
       "         [ 0.7729, -0.4025,  1.6836,  ..., -0.0291, -0.9190, -0.1099],\n",
       "         [-1.2949,  0.3499, -0.3251,  ..., -0.7071,  0.2075,  0.4789]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 2.0811, -0.4887, -0.6066,  ...,  0.8068,  0.7034, -0.1795],\n",
       "         [-0.2306, -0.7691,  1.9282,  ..., -1.2936, -0.9473, -1.8728],\n",
       "         [ 1.0906,  0.4725, -0.7905,  ...,  0.4169,  0.1875,  1.0177],\n",
       "         ...,\n",
       "         [ 0.2809,  0.1948, -0.6708,  ..., -0.1445, -0.6332,  0.3158],\n",
       "         [-0.4372,  1.0761,  1.3773,  ..., -0.2206,  0.9930,  1.1679],\n",
       "         [-0.2470, -1.1347,  0.0704,  ..., -0.1052, -0.3135, -0.8821]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.5446,  1.1419, -0.5454,  ..., -1.0723, -0.3264,  0.8826],\n",
       "         [ 0.2358,  0.1153,  0.4700,  ...,  2.1507, -0.1045,  0.9946],\n",
       "         [ 1.4426, -1.6477, -1.8963,  ..., -1.9014, -0.9741, -1.6742],\n",
       "         ...,\n",
       "         [ 1.5870, -1.9286, -0.2662,  ..., -0.9375, -0.4993,  1.1961],\n",
       "         [-1.7605,  1.1865, -0.1560,  ...,  0.6478,  1.0497,  0.9371],\n",
       "         [ 1.1118,  0.2090, -0.5390,  ..., -0.5708, -0.3439,  0.0792]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.2393, -0.3389,  0.0125,  ...,  0.5514,  1.6474, -0.6015],\n",
       "         [-1.1620, -0.0434,  0.1917,  ..., -1.7708,  1.3750, -1.3014],\n",
       "         [-0.1237,  0.1232, -1.6365,  ...,  0.9669,  0.0377,  2.3705],\n",
       "         ...,\n",
       "         [-0.0540,  0.4746,  0.7632,  ..., -1.7406,  0.0932, -1.1315],\n",
       "         [ 0.8113, -1.1437, -1.4723,  ...,  0.2584,  0.2177,  0.2566],\n",
       "         [-0.4924,  1.0120,  0.6956,  ..., -0.5108, -0.4441,  0.4797]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.1719,  1.8321,  0.0307,  ..., -1.4370, -1.1493, -0.2076],\n",
       "         [-0.6759,  0.3388,  0.7022,  ..., -2.6960,  1.0833,  0.7652],\n",
       "         [ 1.1652, -0.5203,  0.8843,  ...,  0.0648,  0.2417, -0.1212],\n",
       "         ...,\n",
       "         [-0.6048,  0.3715, -1.8699,  ...,  0.4777,  0.7575,  0.5685],\n",
       "         [-1.1662, -0.6885,  0.1247,  ...,  0.0644,  0.3910,  1.0581],\n",
       "         [ 1.4237, -0.7319, -0.0907,  ...,  0.0154, -0.0884,  1.5955]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.2414,  0.0278,  0.2994,  ...,  0.3396,  0.4909,  0.2233],\n",
       "         [-0.2767, -0.4276, -0.7669,  ...,  0.5298,  0.1770,  0.0678],\n",
       "         [-0.1815,  0.1959,  0.7918,  ...,  1.4731, -0.6599, -0.8082],\n",
       "         ...,\n",
       "         [-0.9294,  1.2968,  2.2636,  ..., -2.0313, -0.2257, -1.6943],\n",
       "         [ 0.2526, -0.5368,  0.0042,  ...,  0.8998, -0.7501,  0.7756],\n",
       "         [ 1.8080,  0.2787,  1.4280,  ..., -0.3070, -1.3409,  1.3284]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.3283,  1.4074,  0.8675,  ..., -1.0486,  1.3326, -0.7142],\n",
       "         [ 0.4575, -2.3747,  0.1368,  ..., -0.7845, -1.3719,  1.1012],\n",
       "         [-1.3749,  1.2850,  1.3558,  ...,  0.6324,  0.9725, -0.7701],\n",
       "         ...,\n",
       "         [-1.6988, -0.5738,  0.3684,  ...,  1.0137,  0.1810,  0.4858],\n",
       "         [-0.6776, -0.5647,  0.9352,  ..., -0.3800,  0.3525, -1.5217],\n",
       "         [-0.6323,  0.1645,  1.2674,  ..., -0.9296, -0.9567,  0.5378]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.6549, -0.8537, -0.8225,  ..., -0.3482, -1.1398,  1.5464],\n",
       "         [-1.8219,  0.9911, -0.4811,  ..., -1.3473,  0.3142,  1.9444],\n",
       "         [ 0.2954,  0.8395, -1.0519,  ...,  1.7130, -0.5922,  0.1435],\n",
       "         ...,\n",
       "         [ 1.5305,  0.0670, -0.1429,  ...,  0.0274,  1.0145,  0.9874],\n",
       "         [ 0.1836,  0.2119, -0.0533,  ..., -0.3015,  0.4798,  2.1749],\n",
       "         [-0.1252,  1.3358, -0.8761,  ..., -0.4072,  0.3408, -0.2488]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.6923, -0.3363, -1.0188,  ...,  0.4720, -1.4035, -0.4972],\n",
       "         [ 0.8849, -1.9049,  0.3643,  ..., -1.0300,  0.1153, -0.2687],\n",
       "         [ 0.4951,  3.8610, -0.1539,  ...,  0.3540,  0.6542,  0.2663],\n",
       "         ...,\n",
       "         [-0.0659, -0.8866,  0.3140,  ..., -0.2122,  0.0044,  0.7243],\n",
       "         [ 0.6441,  0.5993,  0.4108,  ...,  1.4497, -0.6163, -0.6315],\n",
       "         [ 0.9330, -1.5646,  0.2837,  ..., -1.7827, -0.2384,  0.7593]],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.7156, -1.0421,  0.6266,  ..., -1.6096,  0.8201,  2.2344],\n",
       "         [ 0.4541, -0.1076, -1.1849,  ..., -0.5843,  0.7747,  0.4335],\n",
       "         [ 1.1672,  0.2443,  1.7625,  ..., -1.0886, -0.8783,  0.0426],\n",
       "         ...,\n",
       "         [ 1.3608,  1.6578, -0.4955,  ..., -0.5900,  0.0832,  1.4340],\n",
       "         [-1.2295,  2.0904, -1.5459,  ..., -1.5563, -0.8400, -1.9047],\n",
       "         [-1.4365,  0.2769, -0.8063,  ...,  1.2359, -0.6476, -1.7906]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.8659, -0.6101, -0.4861,  ...,  0.1126, -0.9398,  0.6899],\n",
       "         [-0.1141, -0.6459,  1.1626,  ...,  2.0315,  0.5255, -1.1865],\n",
       "         [ 0.3333, -1.5983, -1.8233,  ...,  1.0828, -0.0234,  0.1296],\n",
       "         ...,\n",
       "         [-1.2137, -0.5294, -0.8974,  ..., -0.3978, -2.0166,  1.0965],\n",
       "         [ 0.3867, -1.2510, -0.1558,  ..., -0.4065, -0.5282,  0.1493],\n",
       "         [ 0.9304,  0.8951,  1.9249,  ...,  0.9115,  1.0710, -1.9439]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.2759,  0.8359, -1.9518,  ...,  1.0997, -0.3114,  0.6572],\n",
       "         [ 0.7572, -0.9702,  0.2668,  ..., -0.9755,  2.5649, -0.2279],\n",
       "         [-0.4995, -1.2687, -0.5127,  ...,  0.4394,  1.0229,  0.7527],\n",
       "         ...,\n",
       "         [ 0.7737,  0.1014,  0.1202,  ..., -2.5042, -1.0161,  2.1148],\n",
       "         [ 1.5572, -1.7705, -0.2519,  ...,  1.3213, -0.5427, -0.4883],\n",
       "         [-2.0664, -0.3955,  0.2792,  ..., -0.6791, -0.0542, -0.8572]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.4043,  0.0566,  0.1755,  ..., -1.9036,  0.1314,  0.3505],\n",
       "         [-0.3064, -0.2836,  0.0891,  ..., -0.5212, -0.5615, -0.4481],\n",
       "         [ 1.1748,  0.4423, -1.6226,  ..., -0.2896,  2.2508,  0.2473],\n",
       "         ...,\n",
       "         [-0.4929, -0.5340,  0.0066,  ..., -0.9103, -0.7050, -0.0182],\n",
       "         [ 1.3749,  1.6614, -1.1435,  ..., -0.5366,  0.3971, -0.1023],\n",
       "         [ 0.3130, -1.2017,  0.0519,  ...,  0.3814, -0.8031, -0.1494]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.2413,  0.0961,  0.2601,  ..., -1.5762,  0.7644,  1.5677],\n",
       "         [-0.6905, -2.6379,  0.8195,  ..., -0.0538, -0.3408, -0.7831],\n",
       "         [-0.7112, -0.3333, -0.5584,  ...,  0.1134,  0.3528, -0.6811],\n",
       "         ...,\n",
       "         [-0.0323, -1.1461,  0.5401,  ...,  1.9656,  0.2432, -0.7483],\n",
       "         [ 0.5582,  0.4296, -0.8909,  ...,  0.7031, -1.0636, -0.6890],\n",
       "         [ 1.2910, -0.5787, -0.4859,  ..., -0.3057,  0.6194,  0.8625]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.6439, -0.2894, -0.1633,  ..., -0.7217,  0.7092, -0.6977],\n",
       "         [-1.1270, -0.5808, -0.7851,  ..., -0.0411, -2.5526, -0.5446],\n",
       "         [-1.0638, -0.2964,  0.3628,  ..., -1.5659,  0.9278,  0.2902],\n",
       "         ...,\n",
       "         [ 1.6360,  0.7937, -0.8681,  ...,  0.4205,  0.0807,  0.0780],\n",
       "         [ 2.3450, -0.6599,  0.0698,  ...,  0.1919, -0.4657,  0.3580],\n",
       "         [ 0.2962, -0.5251, -1.1825,  ..., -0.3207,  1.9833,  1.1669]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.6087,  0.9495,  0.5558,  ..., -0.1645, -0.3499, -1.2568],\n",
       "         [ 0.5462, -2.2292, -0.4271,  ...,  0.7248, -0.1997,  0.8678],\n",
       "         [-1.1531,  0.3603, -1.0074,  ..., -0.2573,  1.3318, -0.6495],\n",
       "         ...,\n",
       "         [ 0.8897, -1.5352,  3.2148,  ...,  1.9878, -0.1196,  1.1742],\n",
       "         [ 0.6781, -0.4002, -0.1988,  ..., -0.2261, -1.4518, -1.1674],\n",
       "         [ 0.3046,  1.2279,  0.5713,  ..., -1.0963, -0.3841,  1.3120]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.9097, -0.0547,  0.2554,  ..., -1.0428, -0.0248, -0.5411],\n",
       "         [ 1.2294, -0.7583,  0.4323,  ...,  0.8023, -1.3489, -1.1726],\n",
       "         [-0.5514, -1.1993,  0.2459,  ...,  0.7941,  0.9333,  2.1052],\n",
       "         ...,\n",
       "         [-0.0221, -0.4793, -1.3335,  ..., -0.3148, -0.3935,  0.3300],\n",
       "         [-0.0113,  0.2139,  0.4277,  ...,  0.2400,  2.5339,  0.6777],\n",
       "         [ 0.3381, -0.3725, -1.7349,  ...,  0.1671,  3.1001,  0.7414]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.3982, -0.0808,  1.6898,  ..., -0.6752, -1.4677,  0.6609],\n",
       "         [ 0.7675,  1.2558, -1.1332,  ...,  0.3554, -0.9811,  0.3603],\n",
       "         [ 0.5096, -0.4308, -0.5663,  ...,  0.9002,  0.4039,  0.8038],\n",
       "         ...,\n",
       "         [-0.8870, -0.2908, -0.9789,  ...,  0.4908,  0.1763,  1.4460],\n",
       "         [-0.7384,  2.5312, -0.1173,  ..., -2.0369,  1.3446, -0.2611],\n",
       "         [ 1.5566, -1.2183, -0.7260,  ...,  1.7593,  0.2277, -0.6263]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.0612e-01, -9.4052e-01,  2.5276e-01,  ...,  6.7060e-01,\n",
       "          -6.1288e-01, -3.6656e-01],\n",
       "         [-1.0880e+00, -1.2073e+00,  4.5505e-01,  ..., -1.7576e-01,\n",
       "           2.4291e+00, -4.1679e-01],\n",
       "         [ 1.0305e+00,  3.2366e-01,  2.0389e+00,  ..., -1.5249e-01,\n",
       "           6.9397e-01, -1.1710e+00],\n",
       "         ...,\n",
       "         [ 3.1955e-03, -7.2588e-01,  7.1965e-01,  ...,  1.7696e-01,\n",
       "          -3.0550e-01, -7.3968e-02],\n",
       "         [ 8.5899e-01,  1.2502e+00, -5.3862e-01,  ...,  3.0529e-01,\n",
       "          -1.3483e+00,  2.1382e-01],\n",
       "         [ 3.2677e+00,  1.6482e-01,  5.5372e-01,  ..., -1.7250e+00,\n",
       "          -1.7193e-03,  3.5585e-01]], device='cuda:0'),\n",
       " tensor([[ 2.5141, -0.0082,  0.0637,  ...,  0.2761,  0.4985, -0.3390],\n",
       "         [-0.6325,  0.5419, -0.3916,  ..., -0.0918, -0.6065,  0.4810],\n",
       "         [ 0.7004,  0.7527, -0.0476,  ...,  0.7325,  1.3962,  0.6335],\n",
       "         ...,\n",
       "         [-0.7555, -0.1184, -0.5051,  ...,  0.3043,  0.7593,  0.0090],\n",
       "         [-1.4557,  1.4805,  1.6622,  ..., -1.2048,  0.5003,  0.0438],\n",
       "         [-0.9540, -0.5429,  0.6557,  ..., -0.1520, -1.1816,  0.6474]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1747, -0.4776, -2.5390,  ...,  0.6300,  0.6826, -0.7630],\n",
       "         [-0.3768, -1.0182,  0.9438,  ..., -0.5059, -0.9524, -0.7910],\n",
       "         [-1.0071, -0.9976, -0.6234,  ..., -0.6198,  1.3753, -0.0663],\n",
       "         ...,\n",
       "         [ 0.7912,  0.4197,  0.6456,  ...,  0.3055,  0.1337, -1.3241],\n",
       "         [ 0.3522,  0.3416, -1.9932,  ...,  1.5891,  2.0253, -0.0229],\n",
       "         [-0.3630,  0.1427,  0.0186,  ...,  0.4095, -1.7969, -0.0071]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.9867, -1.6941,  0.9382,  ..., -1.9299, -0.1251,  1.3395],\n",
       "         [ 1.0148, -0.9193, -1.1252,  ..., -1.1132, -0.5458, -0.8192],\n",
       "         [-0.1923, -0.6436,  0.3227,  ..., -0.4658, -0.1293,  0.5232],\n",
       "         ...,\n",
       "         [ 0.3701, -0.0484,  0.5985,  ..., -1.8258, -0.0872,  1.9429],\n",
       "         [-2.3381,  0.1966,  0.4687,  ...,  0.2216, -1.8095, -0.3144],\n",
       "         [ 0.3982,  0.6626,  0.1160,  ...,  0.2332,  0.0768,  0.3584]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.1566,  0.6893, -1.5665,  ...,  0.0338, -1.3509,  0.2763],\n",
       "         [ 0.6068,  1.0896,  0.8588,  ...,  0.6021, -0.2365, -1.4298],\n",
       "         [ 0.5647,  1.6693, -0.1426,  ...,  0.8704,  0.6534,  0.7872],\n",
       "         ...,\n",
       "         [-1.9840,  1.3640, -0.1723,  ...,  0.0516,  0.2348, -0.4480],\n",
       "         [ 0.3919,  0.0542,  0.9284,  ...,  0.2651, -1.3431, -0.5166],\n",
       "         [-0.0508, -1.6093, -1.1963,  ...,  1.0630,  0.5023,  1.0001]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0973, -1.7022, -0.6832,  ...,  0.0769,  0.0215,  0.0553],\n",
       "         [ 1.0216,  1.7943, -0.8044,  ..., -0.4917,  1.4455,  0.6002],\n",
       "         [-1.3404,  0.0425, -0.2365,  ...,  0.4439,  2.2308,  0.3543],\n",
       "         ...,\n",
       "         [-0.1564,  0.0628,  1.0988,  ..., -0.2967, -1.5474, -0.1359],\n",
       "         [ 0.6162,  1.6158,  2.6588,  ...,  0.9503, -0.3774,  0.2776],\n",
       "         [ 0.5674,  0.8446, -0.1499,  ..., -0.8168,  1.1438, -1.2750]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.7788,  1.1828, -0.1190,  ..., -0.6501,  0.3745,  0.1303],\n",
       "         [ 0.1115, -0.8365, -0.5491,  ...,  2.9583, -0.1697,  1.7945],\n",
       "         [ 0.5907,  0.5874,  1.3801,  ...,  0.5588, -0.0667,  0.4230],\n",
       "         ...,\n",
       "         [-1.4590,  0.8428, -0.2391,  ..., -0.0221, -0.6189,  0.3524],\n",
       "         [-0.1634,  0.3885, -1.0143,  ...,  0.2594, -0.0307, -0.5234],\n",
       "         [-1.6804,  0.1212, -1.7288,  ...,  0.9276, -0.4847,  0.2753]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.6749, -0.0849,  1.5661,  ..., -0.0617, -0.4355,  1.1475],\n",
       "         [-0.5686,  0.9125, -0.7579,  ...,  0.2317, -0.8800,  0.6358],\n",
       "         [ 1.0402,  1.2473, -1.9247,  ..., -1.3058,  0.9271,  0.3422],\n",
       "         ...,\n",
       "         [-1.3143, -2.7799,  0.9536,  ...,  0.7334, -1.1784,  0.2688],\n",
       "         [-1.7707, -0.8829,  0.7791,  ...,  0.8642, -0.3381, -0.4949],\n",
       "         [-0.3550, -0.0427,  0.9923,  ...,  0.8559,  0.0420, -1.3819]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.6519,  1.1024,  1.2171,  ...,  1.3369, -0.4917, -1.4450],\n",
       "         [ 0.0993, -0.1428, -0.7838,  ...,  0.8016,  0.9279,  1.8694],\n",
       "         [-0.6145, -0.0235, -0.4309,  ..., -0.7900,  2.2000, -0.7349],\n",
       "         ...,\n",
       "         [-0.5203, -0.6163, -1.5838,  ..., -0.4250,  1.5515, -0.2904],\n",
       "         [-0.4287,  0.0862,  0.2057,  ...,  0.4689, -1.1445,  0.3535],\n",
       "         [ 0.0032,  0.0868, -0.5249,  ...,  0.6950,  0.8109,  0.0740]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.5948, -0.3756,  2.4995,  ..., -0.2324, -0.2820,  0.2923],\n",
       "         [-0.1838, -1.0915, -0.5097,  ...,  0.6040,  0.1302,  1.2639],\n",
       "         [-2.3394, -0.0846, -1.2664,  ...,  1.2099, -0.7761,  0.3324],\n",
       "         ...,\n",
       "         [ 0.8194,  0.2786,  1.4945,  ...,  0.7375, -0.6284, -0.4825],\n",
       "         [-0.1667, -1.0680,  0.9132,  ...,  1.7352, -2.6232, -0.8701],\n",
       "         [ 2.5224, -0.2903,  1.5143,  ..., -0.7037, -0.6211,  1.3416]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.2656, -0.2057, -1.9855,  ..., -1.1583,  0.3071, -0.5005],\n",
       "         [-0.9353, -0.1269, -2.4029,  ...,  0.1820, -2.2981,  0.8386],\n",
       "         [-0.1918,  0.5866, -0.0658,  ...,  1.8785,  1.5149,  0.6318],\n",
       "         ...,\n",
       "         [-0.5876,  0.8990,  0.9788,  ...,  0.6877,  1.1669,  0.8052],\n",
       "         [-0.3915, -0.1367,  0.1898,  ..., -0.3711, -0.4873, -0.8237],\n",
       "         [ 0.7888,  0.8213, -0.0617,  ...,  0.8292,  1.2404, -1.8115]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.4588,  1.0657,  1.8747,  ..., -0.3494, -1.0092, -0.1798],\n",
       "         [ 1.0390,  0.6668,  0.1738,  ..., -1.7196, -0.0126,  0.0601],\n",
       "         [ 0.3154,  0.5945, -0.1307,  ..., -0.4499, -1.9669,  0.3579],\n",
       "         ...,\n",
       "         [-1.2465, -0.4037,  0.6441,  ...,  0.9259, -1.5170,  0.0697],\n",
       "         [-0.7487,  1.6284, -0.5996,  ..., -0.6340,  0.8206,  0.4532],\n",
       "         [ 0.4607,  0.6147,  0.6007,  ..., -0.4050,  0.3591, -0.0159]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1877, -1.1475,  1.0814,  ...,  2.0917,  0.1822, -0.7402],\n",
       "         [-0.6981,  1.1935,  2.3768,  ...,  0.7977, -1.0398, -0.6307],\n",
       "         [ 1.0212,  2.6452,  0.5986,  ..., -1.4644, -1.1091,  2.0888],\n",
       "         ...,\n",
       "         [ 0.7120, -0.5623,  0.6773,  ...,  0.5489,  1.4405,  1.0326],\n",
       "         [-1.7055, -0.4736, -0.1993,  ..., -1.3945,  1.4444,  1.4499],\n",
       "         [-0.2562,  1.0269,  1.0889,  ...,  1.6886,  1.2329,  0.1568]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.6681,  0.0800, -0.4144,  ..., -0.0332,  0.6934, -1.8388],\n",
       "         [ 0.2764,  0.0820, -0.6288,  ...,  0.4398,  0.2432,  1.2765],\n",
       "         [-0.6642, -0.0299,  1.3511,  ...,  0.0198, -0.2862, -0.0116],\n",
       "         ...,\n",
       "         [-1.6549,  0.5004,  1.5419,  ...,  2.3501,  1.1717,  1.5819],\n",
       "         [-0.9212, -0.8114,  0.7570,  ..., -0.6782,  0.8561,  0.7248],\n",
       "         [-0.2944, -1.1156, -0.6620,  ...,  1.2626, -0.1466, -0.6509]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.6912,  2.5271,  1.0557,  ..., -0.7824, -0.2977,  2.4874],\n",
       "         [ 0.4403, -0.4857,  0.4623,  ..., -1.0547,  0.2252, -0.1323],\n",
       "         [ 1.3032, -0.0156, -0.5861,  ..., -0.4386, -0.2608, -1.1431],\n",
       "         ...,\n",
       "         [-1.1767,  0.3791,  1.2465,  ..., -0.4029, -0.4280, -0.8467],\n",
       "         [ 0.2635, -0.1471,  2.1451,  ..., -0.8117,  1.3838,  0.3692],\n",
       "         [-0.2293,  0.0156,  2.0911,  ..., -0.6420, -0.0320, -1.0759]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.0231, -0.1514, -1.0101,  ..., -1.3780,  0.6506, -0.2999],\n",
       "         [ 0.1272,  0.1356, -1.0831,  ...,  0.2684, -0.1070, -1.7723],\n",
       "         [-0.4511,  0.5115, -1.8025,  ..., -0.6001, -1.3723, -0.8276],\n",
       "         ...,\n",
       "         [ 0.2152, -0.1229,  0.3193,  ...,  0.0147, -0.7248, -0.4225],\n",
       "         [-0.0695,  0.1221, -0.7288,  ...,  1.8701,  0.6434,  0.3083],\n",
       "         [ 0.5840, -0.4736, -1.5582,  ..., -0.8403, -1.9280, -2.5567]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.4635,  0.9539,  0.0337,  ..., -0.2806,  1.4371, -0.5447],\n",
       "         [ 0.2683, -0.2073, -0.1533,  ..., -1.3590, -0.3096,  0.4733],\n",
       "         [-0.2921, -0.7390, -0.0546,  ...,  0.8805,  0.5531,  1.2542],\n",
       "         ...,\n",
       "         [ 0.4972,  0.6325, -1.1623,  ..., -0.8968,  2.3440,  0.8542],\n",
       "         [ 1.3431,  0.3097, -1.0637,  ...,  1.9996, -0.3853, -0.3818],\n",
       "         [-1.0367,  0.7224,  0.6193,  ...,  0.5369, -0.2956, -0.5913]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.8843,  0.1253, -0.5165,  ..., -0.5443, -1.6132,  0.1986],\n",
       "         [ 1.1680,  0.2369, -0.4732,  ..., -0.8622, -0.8994,  1.1649],\n",
       "         [ 0.6109,  2.5959, -0.5388,  ...,  1.8328,  0.5357, -0.2682],\n",
       "         ...,\n",
       "         [ 0.4523,  0.2551, -1.0084,  ...,  0.5485, -0.4084, -0.0753],\n",
       "         [-0.6765, -1.5171,  0.2424,  ..., -2.1978, -0.4300, -1.0489],\n",
       "         [ 0.4999, -0.7542, -1.3262,  ..., -0.8427, -0.1032,  0.6966]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.6053,  0.1626, -1.7404,  ..., -0.7908, -0.1562, -2.0083],\n",
       "         [-1.0384, -0.9027,  1.1044,  ...,  1.4503, -1.1666, -0.5933],\n",
       "         [-1.4808, -0.1353,  1.4122,  ..., -0.7128,  1.2040,  0.7886],\n",
       "         ...,\n",
       "         [-0.9032, -0.2426, -1.6681,  ..., -0.1976, -1.6069,  0.3519],\n",
       "         [ 0.2225,  2.6009, -1.4099,  ...,  0.0989, -1.6207, -0.8997],\n",
       "         [-0.3717,  0.8500, -0.6108,  ..., -0.6045, -1.4279,  2.3515]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.2504, -1.0147, -0.6543,  ...,  0.0509, -0.4259, -0.8923],\n",
       "         [-0.5225,  1.1215,  1.1178,  ..., -0.7277,  1.2412,  1.4973],\n",
       "         [-0.9304, -0.1982,  0.5336,  ..., -0.9096,  0.0906,  0.3340],\n",
       "         ...,\n",
       "         [-1.0506,  0.7604, -1.8353,  ..., -0.5609,  0.3359, -0.6292],\n",
       "         [ 1.4212, -2.5574, -0.9270,  ...,  0.2788, -1.4393,  0.0563],\n",
       "         [-0.2025,  2.7701, -0.0987,  ...,  0.1957, -0.2897,  2.5370]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 2.2584, -0.2267, -0.5306,  ...,  0.8384,  1.1406,  0.9273],\n",
       "         [ 1.0303,  0.6291, -1.0181,  ..., -0.0664, -0.6507, -0.5208],\n",
       "         [ 0.9809, -0.3661, -0.3740,  ...,  0.3397, -0.2467,  1.4003],\n",
       "         ...,\n",
       "         [-1.2301,  0.1408, -0.2261,  ...,  0.4869, -2.3733, -2.3817],\n",
       "         [-2.7332, -0.6713, -0.7568,  ..., -1.0455,  1.9680,  0.0732],\n",
       "         [ 0.3347, -1.6107, -0.0457,  ..., -0.9954, -1.7074,  0.8261]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.5129, -0.0337, -0.8045,  ...,  1.7557, -1.2328,  0.4181],\n",
       "         [-1.1171,  0.2308,  1.2340,  ...,  0.6011,  1.2716, -0.2555],\n",
       "         [-0.1193,  0.8181, -1.3370,  ...,  0.4556, -1.0711,  0.9561],\n",
       "         ...,\n",
       "         [ 1.1500, -0.8326, -0.4126,  ...,  0.6654, -0.4440,  0.1524],\n",
       "         [-0.5866,  1.2597,  0.4448,  ..., -1.2968,  0.6491, -0.3315],\n",
       "         [ 0.8695, -2.0083,  0.3735,  ..., -2.2927,  1.1382, -1.2003]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.1044, -0.9841, -0.4552,  ..., -0.5809,  0.3155, -0.3644],\n",
       "         [ 1.9750,  0.1567,  0.1959,  ...,  0.1847, -0.7084,  0.1113],\n",
       "         [ 0.8883, -0.7416, -0.4169,  ...,  0.2087,  0.2728, -0.6904],\n",
       "         ...,\n",
       "         [-0.9068,  1.1764, -0.8900,  ..., -0.4265, -0.7734,  1.1270],\n",
       "         [-0.2175,  1.4889, -0.4258,  ...,  0.1113,  0.4822, -0.7878],\n",
       "         [-0.1395, -0.0708,  0.1782,  ...,  1.6537,  1.5337, -0.0179]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.1847,  0.8936, -0.5191,  ..., -0.2452,  1.9837, -1.0729],\n",
       "         [-0.3631, -0.4189, -1.7036,  ...,  0.1808,  0.8359,  1.1165],\n",
       "         [-0.5018, -0.1947, -0.0378,  ..., -0.1873, -0.9211,  0.1128],\n",
       "         ...,\n",
       "         [-0.0091, -0.6612,  0.0079,  ...,  0.9768,  0.9945,  1.4535],\n",
       "         [-2.6891,  0.6757, -1.4919,  ..., -0.7073, -2.3347, -1.7501],\n",
       "         [-0.0468, -1.5998, -0.1996,  ..., -1.6249, -0.1958,  0.7058]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.5725, -1.2804, -1.5524,  ...,  0.8839, -0.3309,  0.7447],\n",
       "         [-1.5047, -0.9003, -0.0509,  ...,  0.4798, -1.2934, -1.2170],\n",
       "         [-0.3821,  1.1043,  0.9079,  ..., -0.4726,  0.1556,  2.3649],\n",
       "         ...,\n",
       "         [-0.5480,  1.1208, -0.5383,  ...,  0.0860,  0.1938,  1.7594],\n",
       "         [ 0.7189,  1.8310,  1.3270,  ..., -0.2501, -0.3623,  0.3485],\n",
       "         [-1.5993,  0.0646, -0.8888,  ..., -0.2030, -0.5854,  0.6367]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.1896e+00, -9.0893e-01,  7.7558e-02,  ..., -1.5736e+00,\n",
       "           9.3986e-01,  6.1661e-01],\n",
       "         [-6.9922e-01, -2.0883e-01,  2.8607e-01,  ...,  6.2571e-01,\n",
       "           1.0204e-01, -2.2836e+00],\n",
       "         [-6.5807e-02, -4.2650e-04,  1.2567e+00,  ..., -7.8758e-01,\n",
       "           8.9929e-01, -8.9484e-01],\n",
       "         ...,\n",
       "         [ 1.7502e-01, -8.0723e-01, -7.5554e-01,  ..., -1.2516e-01,\n",
       "           2.5844e-01,  1.8876e-01],\n",
       "         [-2.4386e-01,  3.4764e-01,  7.8615e-02,  ..., -1.8216e-01,\n",
       "          -6.4503e-01,  7.5751e-01],\n",
       "         [ 8.4180e-01,  8.7714e-01, -6.9176e-01,  ..., -1.2710e+00,\n",
       "          -1.9311e-01,  2.0264e+00]], device='cuda:0'),\n",
       " tensor([[ 0.9097,  0.6850, -0.5359,  ..., -0.6662, -0.0862,  1.1003],\n",
       "         [-0.0526, -0.0071, -0.1534,  ..., -0.5427,  1.7776, -0.2609],\n",
       "         [ 1.0220,  0.8057, -0.8692,  ..., -0.3162,  0.5364,  0.1691],\n",
       "         ...,\n",
       "         [-0.0152, -0.4353,  0.4383,  ...,  0.2997,  1.5261, -0.9104],\n",
       "         [ 2.0655,  1.4898, -1.2580,  ...,  1.8081, -1.9170, -1.4772],\n",
       "         [ 0.4927, -0.7067, -2.5794,  ..., -1.3280, -0.3089,  2.4483]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0995,  0.1801,  1.2832,  ...,  1.2033, -1.4497, -0.8823],\n",
       "         [-0.6085,  1.5217,  0.2462,  ...,  0.4055, -0.3237,  0.4800],\n",
       "         [-0.2884, -0.5159,  0.6222,  ..., -0.4231,  0.6746, -0.2109],\n",
       "         ...,\n",
       "         [-0.2648,  0.6603, -1.4745,  ...,  0.2875,  0.4649, -0.0588],\n",
       "         [ 1.4560,  0.3946, -1.0846,  ...,  0.0078, -0.9394, -0.2346],\n",
       "         [-1.4484,  2.0613, -0.0892,  ..., -1.2684, -0.4576, -0.9898]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.9373,  1.1480, -0.2179,  ...,  0.3827,  1.5766, -0.0107],\n",
       "         [-0.0277, -1.0097,  1.6731,  ...,  0.1720, -0.9794,  0.3183],\n",
       "         [-1.0674, -0.2720,  0.2609,  ...,  1.3886,  0.4207, -1.5709],\n",
       "         ...,\n",
       "         [-0.3764,  0.1849,  1.0433,  ..., -0.9387,  0.8194, -0.2006],\n",
       "         [ 0.1995, -3.3284,  1.1536,  ..., -0.2894, -0.5288,  0.8000],\n",
       "         [-0.2999, -0.0352,  0.1022,  ..., -0.6619,  0.7403, -0.5488]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.7639, -0.3907, -0.4591,  ..., -0.9840, -0.4918,  0.4587],\n",
       "         [ 0.3023,  1.4249,  1.6326,  ..., -1.6538, -0.2424, -0.0268],\n",
       "         [-0.7774, -0.0991,  0.0726,  ..., -0.2212, -0.3041, -0.9221],\n",
       "         ...,\n",
       "         [ 0.0081,  0.5826, -0.8302,  ...,  0.9216, -0.4334,  1.5367],\n",
       "         [-0.8670,  1.1462, -0.3678,  ..., -2.4792,  0.2079, -0.1459],\n",
       "         [ 1.5140, -1.3540,  0.1669,  ..., -1.7492, -0.1315,  0.5858]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.6880, -0.5141,  0.0505,  ...,  1.6086,  0.8279, -0.4959],\n",
       "         [-1.3438,  0.6639, -0.3204,  ..., -1.6883, -0.5234, -0.3603],\n",
       "         [ 0.8568,  1.2963, -1.3361,  ..., -0.1705,  0.8706, -0.0244],\n",
       "         ...,\n",
       "         [-0.9136,  0.8886, -1.2229,  ...,  0.9868,  0.3729, -1.2501],\n",
       "         [-0.3489,  0.3880, -1.6716,  ..., -0.6252,  0.8042, -0.7471],\n",
       "         [ 0.7811,  0.6499,  1.7767,  ..., -1.1753, -0.4767,  2.0183]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.3266,  1.6867,  0.3973,  ..., -0.4393, -1.6395, -1.8643],\n",
       "         [-0.8842, -0.2953,  0.3190,  ...,  0.8204, -0.2556,  1.2932],\n",
       "         [-0.6439, -2.0264, -0.5899,  ..., -0.5406, -0.8493,  0.4431],\n",
       "         ...,\n",
       "         [-1.1688, -2.3590,  1.5100,  ..., -1.9212, -0.4594, -0.6349],\n",
       "         [-0.4363, -0.4571, -0.7007,  ..., -0.8428,  0.8619,  0.5992],\n",
       "         [ 0.6563,  1.1350, -0.6814,  ...,  0.3764, -1.1932, -0.9859]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1195, -1.0185, -1.1056,  ...,  1.2089, -0.5038, -1.6526],\n",
       "         [ 0.3171, -0.1387,  0.3711,  ..., -1.2588,  0.6824, -1.5796],\n",
       "         [ 0.9541, -0.1169,  0.5523,  ..., -0.4998, -0.5525,  1.9056],\n",
       "         ...,\n",
       "         [ 1.4052, -0.3715, -1.0477,  ..., -1.6417,  0.9276,  0.2286],\n",
       "         [-0.5146,  1.0047,  0.6536,  ..., -0.7038,  0.6542, -0.8084],\n",
       "         [ 0.4731, -0.1301, -0.1512,  ..., -0.1755, -0.9779, -0.5001]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.3112,  1.1952,  1.1567,  ..., -0.8905,  2.5069, -1.1633],\n",
       "         [ 0.5091,  0.8158, -1.0420,  ..., -0.8107, -0.6170, -1.8080],\n",
       "         [-0.1172,  0.7190,  1.0048,  ..., -2.5202, -0.2549,  0.3233],\n",
       "         ...,\n",
       "         [ 2.5818,  2.5420,  1.9492,  ...,  0.2280,  0.2640,  0.2628],\n",
       "         [ 1.8092,  0.8474, -1.5178,  ..., -0.5923,  0.5541, -0.0862],\n",
       "         [ 0.1931,  1.0249, -1.0517,  ...,  0.9676, -1.6594, -0.3773]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1956, -1.2764, -1.0875,  ...,  0.1266, -0.2826, -0.7677],\n",
       "         [-0.9111, -0.6049,  0.1596,  ...,  1.4488,  0.4658, -0.5943],\n",
       "         [ 0.5004,  0.9291,  0.8965,  ...,  0.5589, -0.8480,  1.9003],\n",
       "         ...,\n",
       "         [-0.1480,  0.9552,  1.5334,  ..., -2.4756,  0.7627, -0.0643],\n",
       "         [-0.0230, -0.0664,  1.0845,  ..., -2.0530, -1.0514,  0.8268],\n",
       "         [ 0.0853,  0.6720,  0.9278,  ..., -0.9210, -1.2151, -1.0788]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.9475, -0.4524,  0.7416,  ...,  0.2019,  1.3582, -0.4177],\n",
       "         [ 2.0525, -0.5722, -0.4868,  ...,  0.8436,  0.1697, -0.7658],\n",
       "         [-1.0597, -0.8025,  0.6071,  ...,  0.5235, -0.6233, -1.6483],\n",
       "         ...,\n",
       "         [-0.6823, -0.8875,  0.1805,  ...,  0.8103, -0.7576, -0.9676],\n",
       "         [ 0.7041,  0.4508,  1.5434,  ..., -0.4166, -0.7242,  0.7814],\n",
       "         [-1.6249, -0.9505, -0.0479,  ...,  0.4514,  0.8279,  1.0557]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.6773, -0.0983, -1.0955,  ..., -1.2060,  0.8651, -0.4373],\n",
       "         [-0.0213,  0.0879,  0.8832,  ...,  1.0850, -0.4350, -0.8124],\n",
       "         [-0.8826,  0.1052, -0.6709,  ...,  0.9445,  0.7036,  0.4522],\n",
       "         ...,\n",
       "         [ 0.6093,  0.4283,  0.3270,  ...,  0.7572, -0.7149,  1.0264],\n",
       "         [ 0.5112, -2.0328,  0.7397,  ..., -1.0088, -0.4905, -0.7014],\n",
       "         [-0.4428,  0.2901, -0.0446,  ...,  0.0552,  0.1191, -1.5004]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.8373,  0.1471,  1.0147,  ...,  0.4115, -0.4472, -0.5190],\n",
       "         [-0.1520,  1.4782,  0.9648,  ..., -0.3684, -0.2301, -1.3712],\n",
       "         [ 0.0932,  0.3768,  0.1366,  ...,  0.5546,  1.2619, -0.4043],\n",
       "         ...,\n",
       "         [-0.5165,  0.6233,  0.2453,  ...,  0.4926,  0.4955, -0.4906],\n",
       "         [-0.0127,  0.1841, -1.4939,  ...,  1.7583,  0.3288, -1.6551],\n",
       "         [ 1.6676,  0.2417, -0.1930,  ...,  1.8634,  0.2793,  0.6990]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.9950, -1.2517, -0.5965,  ..., -0.0080,  0.5804, -0.3001],\n",
       "         [-1.9075,  0.3731, -0.1615,  ..., -0.7726, -0.0242, -1.2275],\n",
       "         [-0.5009, -0.0539,  0.6157,  ..., -1.7587, -1.0594,  0.3637],\n",
       "         ...,\n",
       "         [ 1.3407, -1.0110,  0.6951,  ..., -0.3057, -0.1247,  0.2466],\n",
       "         [ 0.9919, -0.4666, -0.2524,  ..., -0.7539, -0.0752, -0.7099],\n",
       "         [-0.1589,  0.0417,  0.1390,  ...,  1.9092, -0.6651, -0.0082]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0841, -0.7104, -0.2673,  ..., -0.6620,  0.3173,  0.9764],\n",
       "         [ 0.2117,  0.4912, -0.0832,  ..., -1.5104, -0.4089,  2.5918],\n",
       "         [-0.6484,  1.0216, -0.8030,  ...,  1.9189, -0.9263, -0.1867],\n",
       "         ...,\n",
       "         [-0.8362, -0.2434, -0.0750,  ..., -0.5555,  0.4237,  0.5411],\n",
       "         [ 1.8935,  2.0249, -0.1855,  ...,  0.3032, -0.6446,  0.4326],\n",
       "         [ 0.1381, -0.2607,  0.2634,  ..., -1.3306, -2.2361,  1.4312]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.6395,  0.8172,  1.0848,  ...,  0.3762,  1.1380,  1.1647],\n",
       "         [-0.6832,  2.8299,  1.3320,  ...,  0.9620,  0.2055, -0.9818],\n",
       "         [ 0.7173, -0.6571,  2.1791,  ..., -0.9001, -0.0550,  1.4905],\n",
       "         ...,\n",
       "         [-1.5441,  0.1967, -1.0168,  ...,  0.2167,  1.0509,  0.5621],\n",
       "         [-0.6713, -0.7660, -0.6241,  ...,  1.3059, -0.9231,  1.3273],\n",
       "         [ 0.4424, -0.1458, -0.0886,  ..., -0.9967, -0.6887,  0.9133]],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default Precision\n",
    "-----------------\n",
    "Without ``torch.cuda.amp``, the following simple network executes all ops in default precision (``torch.float32``):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/cuda/memory.py:234: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default precision:\n",
      "Total execution time = 1.924 sec\n",
      "Max memory used by tensors = 1367458816 bytes\n"
     ]
    }
   ],
   "source": [
    "net = make_model(in_size, out_size, num_layers)\n",
    "opt = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "start_timer()\n",
    "for epoch in range(epochs):\n",
    "    for input, target in zip(data, targets):\n",
    "        output = net(input)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad() # set_to_none=True here can modestly improve performance\n",
    "end_timer_and_print(\"Default precision:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding autocast\n",
    "---------------\n",
    "Instances of `torch.cuda.amp.autocast <https://pytorch.org/docs/stable/amp.html#autocasting>`_\n",
    "serve as context managers that allow regions of your script to run in mixed precision.\n",
    "\n",
    "In these regions, CUDA ops run in a dtype chosen by autocast\n",
    "to improve performance while maintaining accuracy.\n",
    "See the `Autocast Op Reference <https://pytorch.org/docs/stable/amp.html#autocast-op-reference>`_\n",
    "for details on what precision autocast chooses for each op, and under what circumstances.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0): # 0 epochs, this section is for illustration only\n",
    "    for input, target in zip(data, targets):\n",
    "        # Runs the forward pass under autocast.\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = net(input)\n",
    "            # output is float16 because linear layers autocast to float16.\n",
    "            assert output.dtype is torch.float16\n",
    "\n",
    "            loss = loss_fn(output, target)\n",
    "            # loss is float32 because mse_loss layers autocast to float32.\n",
    "            assert loss.dtype is torch.float32\n",
    "\n",
    "        # Exits autocast before backward().\n",
    "        # Backward passes under autocast are not recommended.\n",
    "        # Backward ops run in the same dtype autocast chose for corresponding forward ops.\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad() # set_to_none=True here can modestly improve performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding GradScaler\n",
    "-----------------\n",
    "`Gradient scaling <https://pytorch.org/docs/stable/amp.html#gradient-scaling>`_\n",
    "helps prevent gradients with small magnitudes from flushing to zero\n",
    "(\"underflowing\") when training with mixed precision.\n",
    "\n",
    "`torch.cuda.amp.GradScaler <https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler>`_\n",
    "performs the steps of gradient scaling conveniently.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructs scaler once, at the beginning of the convergence run, using default args.\n",
    "# If your network fails to converge with default GradScaler args, please file an issue.\n",
    "# The same GradScaler instance should be used for the entire convergence run.\n",
    "# If you perform multiple convergence runs in the same script, each run should use\n",
    "# a dedicated fresh GradScaler instance.  GradScaler instances are lightweight.\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(0): # 0 epochs, this section is for illustration only\n",
    "    for input, target in zip(data, targets):\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = net(input)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "        # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "        # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "        # otherwise, optimizer.step() is skipped.\n",
    "        scaler.step(opt)\n",
    "\n",
    "        # Updates the scale for next iteration.\n",
    "        scaler.update()\n",
    "\n",
    "        opt.zero_grad() # set_to_none=True here can modestly improve performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All together: \"Automatic Mixed Precision\"\n",
    "------------------------------------------\n",
    "(The following also demonstrates ``enabled``, an optional convenience argument to ``autocast`` and ``GradScaler``.\n",
    "If False, ``autocast`` and ``GradScaler``\\ 's calls become no-ops.\n",
    "This allows switching between default precision and mixed precision without if/else statements.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "\n",
      "Mixed precision:\n",
      "Total execution time = 0.768 sec\n",
      "Max memory used by tensors = 1988372992 bytes\n"
     ]
    }
   ],
   "source": [
    "use_amp = True\n",
    "\n",
    "net = make_model(in_size, out_size, num_layers)\n",
    "opt = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "start_timer()\n",
    "for epoch in range(epochs):\n",
    "    for input, target in zip(data, targets):\n",
    "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "            output = net(input)\n",
    "            print(len(output))\n",
    "            loss = loss_fn(output, target)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        opt.zero_grad() # set_to_none=True here can modestly improve performance\n",
    "end_timer_and_print(\"Mixed precision:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting/modifying gradients (e.g., clipping)\n",
    "--------------------------------------------------------\n",
    "All gradients produced by ``scaler.scale(loss).backward()`` are scaled.  If you wish to modify or inspect\n",
    "the parameters' ``.grad`` attributes between ``backward()`` and ``scaler.step(optimizer)``, you should\n",
    "unscale them first using `scaler.unscale_(optimizer) <https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler.unscale_>`_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0): # 0 epochs, this section is for illustration only\n",
    "    for input, target in zip(data, targets):\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = net(input)\n",
    "            loss = loss_fn(output, target)\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Unscales the gradients of optimizer's assigned params in-place\n",
    "        scaler.unscale_(opt)\n",
    "\n",
    "        # Since the gradients of optimizer's assigned params are now unscaled, clips as usual.\n",
    "        # You may use the same value for max_norm here as you would without gradient scaling.\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=0.1)\n",
    "\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        opt.zero_grad() # set_to_none=True here can modestly improve performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving/Resuming\n",
    "----------------\n",
    "To save/resume Amp-enabled runs with bitwise accuracy, use\n",
    "`scaler.state_dict <https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler.state_dict>`_ and\n",
    "`scaler.load_state_dict <https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler.load_state_dict>`_.\n",
    "\n",
    "When saving, save the scaler state dict alongside the usual model and optimizer state dicts.\n",
    "Do this either at the beginning of an iteration before any forward passes, or at the end of\n",
    "an iteration after ``scaler.update()``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\"model\": net.state_dict(),\n",
    "              \"optimizer\": opt.state_dict(),\n",
    "              \"scaler\": scaler.state_dict()}\n",
    "# Write checkpoint as desired, e.g.,\n",
    "# torch.save(checkpoint, \"filename\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When resuming, load the scaler state dict alongside the model and optimizer state dicts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read checkpoint as desired, e.g.,\n",
    "# dev = torch.cuda.current_device()\n",
    "# checkpoint = torch.load(\"filename\",\n",
    "#                         map_location = lambda storage, loc: storage.cuda(dev))\n",
    "net.load_state_dict(checkpoint[\"model\"])\n",
    "opt.load_state_dict(checkpoint[\"optimizer\"])\n",
    "scaler.load_state_dict(checkpoint[\"scaler\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a checkpoint was created from a run *without* Amp, and you want to resume training *with* Amp,\n",
    "load model and optimizer states from the checkpoint as usual.  The checkpoint won't contain a saved scaler state, so\n",
    "use a fresh instance of ``GradScaler``.\n",
    "\n",
    "If a checkpoint was created from a run *with* Amp and you want to resume training *without* Amp,\n",
    "load model and optimizer states from the checkpoint as usual, and ignore the saved scaler state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference/Evaluation\n",
    "--------------------\n",
    "``autocast`` may be used by itself to wrap inference or evaluation forward passes. ``GradScaler`` is not necessary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Advanced topics\n",
    "---------------\n",
    "See the `Automatic Mixed Precision Examples <https://pytorch.org/docs/stable/notes/amp_examples.html>`_ for advanced use cases including:\n",
    "\n",
    "* Gradient accumulation\n",
    "* Gradient penalty/double backward\n",
    "* Networks with multiple models, optimizers, or losses\n",
    "* Multiple GPUs (``torch.nn.DataParallel`` or ``torch.nn.parallel.DistributedDataParallel``)\n",
    "* Custom autograd functions (subclasses of ``torch.autograd.Function``)\n",
    "\n",
    "If you perform multiple convergence runs in the same script, each run should use\n",
    "a dedicated fresh GradScaler instance.  GradScaler instances are lightweight.\n",
    "\n",
    "If you're registering a custom C++ op with the dispatcher, see the\n",
    "`autocast section <https://pytorch.org/tutorials/advanced/dispatcher.html#autocast>`_\n",
    "of the dispatcher tutorial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Troubleshooting\n",
    "---------------\n",
    "Speedup with Amp is minor\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "1. Your network may fail to saturate the GPU(s) with work, and is therefore CPU bound. Amp's effect on GPU performance\n",
    "   won't matter.\n",
    "\n",
    "   * A rough rule of thumb to saturate the GPU is to increase batch and/or network size(s)\n",
    "     as much as you can without running OOM.\n",
    "   * Try to avoid excessive CPU-GPU synchronization (``.item()`` calls, or printing values from CUDA tensors).\n",
    "   * Try to avoid sequences of many small CUDA ops (coalesce these into a few large CUDA ops if you can).\n",
    "2. Your network may be GPU compute bound (lots of matmuls/convolutions) but your GPU does not have Tensor Cores.\n",
    "   In this case a reduced speedup is expected.\n",
    "3. Matmul dimensions are not Tensor Core-friendly.  Make sure matmuls' participating sizes are multiples of 8.\n",
    "   (For NLP models with encoders/decoders, this can be subtle.  Also, convolutions used to have similar size constraints\n",
    "   for Tensor Core use, but for CuDNN versions 7.3 and later, no such constraints exist.  See\n",
    "   `here <https://github.com/NVIDIA/apex/issues/221#issuecomment-478084841>`_ for guidance.)\n",
    "\n",
    "Loss is inf/NaN\n",
    "~~~~~~~~~~~~~~~\n",
    "First, check if your network fits an `advanced use case<advanced-topics>`.\n",
    "See also `Prefer binary_cross_entropy_with_logits over binary_cross_entropy <https://pytorch.org/docs/stable/amp.html#prefer-binary-cross-entropy-with-logits-over-binary-cross-entropy>`_.\n",
    "\n",
    "If you're confident your Amp usage is correct, you may need to file an issue, but before doing so, it's helpful to gather the following information:\n",
    "\n",
    "1. Disable ``autocast`` or ``GradScaler`` individually (by passing ``enabled=False`` to their constructor) and see if infs/NaNs persist.\n",
    "2. If you suspect part of your network (e.g., a complicated loss function) overflows , run that forward region in ``float32``\n",
    "   and see if infs/NaNs persist.\n",
    "   `The autocast docstring <https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.autocast>`_'s last code snippet\n",
    "   shows forcing a subregion to run in ``float32`` (by locally disabling autocast and casting the subregion's inputs).\n",
    "\n",
    "Type mismatch error (may manifest as CUDNN_STATUS_BAD_PARAM)\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "Autocast tries to cover all ops that benefit from or require casting.\n",
    "`Ops that receive explicit coverage <https://pytorch.org/docs/stable/amp.html#autocast-op-reference>`_\n",
    "are chosen based on numerical properties, but also on experience.\n",
    "If you see a type mismatch error in an autocast-enabled forward region or a backward pass following that region,\n",
    "it's possible autocast missed an op.\n",
    "\n",
    "Please file an issue with the error backtrace.  ``export TORCH_SHOW_CPP_STACKTRACES=1`` before running your script to provide\n",
    "fine-grained information on which backend op is failing.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
